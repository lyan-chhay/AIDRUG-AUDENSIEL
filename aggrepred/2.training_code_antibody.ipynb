{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    r2_score,\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    average_precision_score, \n",
    "    matthews_corrcoef\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import esm\n",
    "from antiberty import AntiBERTyRunner\n",
    "\n",
    "# Custom imports from aggrepred package\n",
    "top_folder_path = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "sys.path.insert(0, top_folder_path)\n",
    "\n",
    "from aggrepred.dataset import *\n",
    "from aggrepred.model import *\n",
    "from aggrepred.utils import *\n",
    "\n",
    "# Seed everything function\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AntibodySeqDataset:\n",
    "    def __init__(self, df,  max_seq_len=700):\n",
    "        self.data = df.copy()\n",
    "        \n",
    "        # Convert scores from string to list\n",
    "        self.data['Hchain_scores'] = self.data['Hchain_scores'].apply(ast.literal_eval)\n",
    "        self.data['Lchain_scores'] = self.data['Lchain_scores'].apply(ast.literal_eval)\n",
    "\n",
    "        # Calculate positive and negative counts for heavy and light chains\n",
    "        self.data['Hchain_count_positive'] = self.data['Hchain_scores'].apply(lambda x: sum(1 for score in x if score > 0))\n",
    "        self.data['Hchain_count_negative'] = self.data['Hchain_scores'].apply(lambda x: sum(1 for score in x if score <= 0))\n",
    "        self.data['Lchain_count_positive'] = self.data['Lchain_scores'].apply(lambda x: sum(1 for score in x if score > 0))\n",
    "        self.data['Lchain_count_negative'] = self.data['Lchain_scores'].apply(lambda x: sum(1 for score in x if score <= 0))\n",
    "\n",
    "        # Compute lengths of heavy and light chains\n",
    "        self.data['Hchain_len'] = self.data['Hchain_scores'].apply(len)\n",
    "        self.data['Lchain_len'] = self.data['Lchain_scores'].apply(len)\n",
    "\n",
    "        # Compute negative-to-positive ratio for heavy and light chains\n",
    "        self.data['Hchain_neg_to_pos_ratio'] = self.data['Hchain_count_negative'] / self.data['Hchain_count_positive']\n",
    "        self.data['Lchain_neg_to_pos_ratio'] = self.data['Lchain_count_negative'] / self.data['Lchain_count_positive']\n",
    "\n",
    "        # Set max sequence length and scaling flag\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0 or idx >= len(self.data):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "        \n",
    "        row = self.data.iloc[idx]\n",
    "        code = row['ID']\n",
    "        H_seq = row['Hchain_sequence']\n",
    "        L_seq = row['Lchain_sequence']\n",
    "        Hchain_scores = row['Hchain_scores']\n",
    "        Lchain_scores = row['Lchain_scores']\n",
    "\n",
    "        # Prepare target vectors for heavy chain\n",
    "        H_y = Hchain_scores[:self.max_seq_len] + [0] * (450 - len(Hchain_scores))\n",
    "        H_y = torch.tensor(H_y)\n",
    "\n",
    "        # Prepare target vectors for light chain\n",
    "        L_y = Lchain_scores[:self.max_seq_len] + [0] * (250 - len(Lchain_scores))\n",
    "        L_y = torch.tensor(L_y)\n",
    "\n",
    "        H_y_bin = (H_y > 0).int()\n",
    "        L_y_bin = (L_y > 0).int()\n",
    "\n",
    "        # Generate binary mask based on sequence length (1 for actual values, 0 for padding)\n",
    "        H_mask = torch.zeros(450, dtype=torch.bool)\n",
    "        H_mask[:len(Hchain_scores)] = True  # Set the first 'len(Hchain_scores)' to 1\n",
    "\n",
    "        L_mask = torch.zeros(250, dtype=torch.bool)\n",
    "        L_mask[:len(Lchain_scores)] = True  # Set the first 'len(Lchain_scores)' to 1\n",
    "\n",
    "        return {\n",
    "            'code': code,\n",
    "            'H_seq': H_seq,\n",
    "            'H_target_reg': H_y,\n",
    "            'H_target_bin': H_y_bin,\n",
    "            'H_mask': H_mask,\n",
    "\n",
    "            'L_seq': L_seq,\n",
    "            'L_target_reg': L_y,\n",
    "            'L_target_bin': L_y_bin,\n",
    "            'L_mask': L_mask  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# DATA\n",
    "# ----------------\n",
    "\n",
    "def custom_collate(batch):\n",
    "    regs_tensor = [item['target_reg'] for item in batch]\n",
    "    max_len = regs_tensor[0].size()[0]\n",
    "    \n",
    "    orig_lens = [item['orig_len'] for item in batch]\n",
    "    max_orig_len = min(max(orig_lens), max_len)  # Ensure max_orig_len is at most max_len\n",
    "    \n",
    "    # print(max_orig_len)\n",
    "    # truncated_encoded_seqs = [item['encoded_seq'][:max_orig_len,:] for item in batch]\n",
    "    codes = [item['code'] for item in batch]\n",
    "    seqs = [item['seq'] for item in batch]\n",
    "    truncated_regs_tensor = [item['target_reg'][ :max_orig_len] for item in batch]\n",
    "    truncated_bins_tensor = [item['target_bin'][:max_orig_len] for item in batch]\n",
    "    \n",
    "    # encoded_seqs_tensor = torch.stack(truncated_encoded_seqs)\n",
    "    target_regs_tensor = torch.stack(truncated_regs_tensor)\n",
    "    target_bins_tensor = torch.stack(truncated_bins_tensor)\n",
    "\n",
    "    return {\n",
    "        'code': codes,\n",
    "        'seq': seqs,\n",
    "        'target_reg': target_regs_tensor,\n",
    "        'target_bin': target_bins_tensor,\n",
    "        'orig_len': torch.tensor(orig_lens)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antibody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_from_checkpoint(model, checkpoint_path, device):\n",
    "    \"\"\"\n",
    "    Loads the model and optimizer state from a checkpoint if it exists.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to load the state into.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n",
    "    - checkpoint_path (str): Path to the checkpoint file.\n",
    "    - device (torch.device): Device to which the model should be moved.\n",
    "    \n",
    "    Returns:\n",
    "    - start_epoch (int): The epoch to start training from.\n",
    "    - best_validation_loss (float): The best validation loss recorded in the checkpoint.\n",
    "    \"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}. Resuming from epoch {start_epoch}')\n",
    "        # print(f'Best validation loss: {best_validation_loss}')\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_validation_loss = float('inf')  # Assuming lower is better for validation loss\n",
    "        print('No checkpoint found.')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    return start_epoch, best_validation_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "df = pd.read_csv(\"../data/csv/antibody.csv\")\n",
    "\n",
    "# train_dataset = AntibodySeqDataset(df[df.split=='train'].sample(frac=0.10, random_state=42))\n",
    "# valid_dataset = AntibodySeqDataset(df[df.split=='valid'].sample(frac=0.10, random_state=42))\n",
    "# test_dataset = AntibodySeqDataset(df[df.split=='test'])\n",
    "train_dataset = AntibodySeqDataset(df[df.split=='train'])\n",
    "valid_dataset = AntibodySeqDataset(df[df.split=='valid'])\n",
    "test_dataset = AntibodySeqDataset(df[df.split=='test'])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': ['4j8r', '7qny', '6al4', '6hkg', '7kpb', '7kqk', '5jor', '4hzl', '7lop', '2vh5', '7jwp', '5a16', '4hj0', '3thm', '7l7e', '8d3a', '6wo5', '4eow', '2gfb', '6k65', '1nsn', '6mfp', '8ef3', '8dn7', '7zf6', '6mi2', '6bli', '8bbo', '1osp', '6fg2', '6dwi', '6xm2'], 'H_seq': ['VKLQESGGEVVRPGTSVKVSCKASGYAFTNYLIEWVKQRPGQGLEWIGVINPGSGDTNYNEKFKGKATLTADKSSSTAYMQLNSLTSDDSAVYFCARSGAAAPTYYAMDYWGQGVSVTVSSAKTTPPSVYPLAPAAAAANSMVTLGCLVKGYFPEPVTVTWNSGSLSGGVHTFPAVLQSDLYTLSSSVTVPSSTWPSETVTCNVAHPASSTKVDKKIVPR', 'EVQLLESGGDLIQPGGSLRLSCAASGVTVSSNYMSWVRQAPGKGLEWVSIIYPGGSTFYADSVKGRFTISRDNSKNTLYLQMHSLRAEDTAVYYCARDLGSGDMDVWGKGTTVTVSSASTKGPSVFPLAPSSSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKS', 'VQLVQSGAEVKKPGSSVKVSCKASGYAFSSYWMNWVRQAPGQGLEWMGQIWPGDSDTNYAQKFQGRVTITADESTSTAYMELSSLRSEDTAVYYCARRETTTVGRYYYAMDYWGQGTTVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPK', 'EVQLLESGGGLVQPGGSLRLSCAASGFTFSSYGMAWVRQAPGKGLEWVSFISATGLSTYFADSVKGRFTISRDTTKNTLYLQMNSLRADDTAVYFCARMRRTMIAFGGNDFWGQGTLVTVSSASTKGPSVFLGCLVKDYFPEPVTVSWNSGATSGVHTFPAVLQSSGLYSLSSVVTVPYICNVNHKPSNTKVDK', 'DVQLVESGGGLVQPGRSLKLSCAASGFTFSAYYMAWVRQAPTKGLEWVASINYDGANTFYRDSVKGRFTVSRDNARSSLYLQMDSLRSEDTATYYCTTEAYGYNSNWFGYWGQGTLVTVSSAKTTPPSVYPNSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSTWPSETVTCNVAHPASSTKVDKKIVPR', 'EVQLLESGGGLVQPGGSLRLSCAASGFTLSSYQMMWVRQAPGKGLEWVAGITGRGGVTGYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKPALDSDQCGFPEAGCIDAWGQGTLVTVSSASTKGPSVFPLAPGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKS', 'EVQLQQSGPELIKPGASVKMSCEASGYIFTEYYIHWVKQIQGRSLEWIGYVHPKTGDVIYNQNFRGKATLTVNRSSNTAYMELHSLTSEDSAVYYCARWDSWGQGTTLTVSSAKTTPPSVYPLAPGCGSSVTLGCLVKGYFPESVTVTWNSGSLSSSVHTFPALLQSGLYTMSSSVTVPSSTWPSQTVTCSVAHPASSTTVDKKLEP', 'EVMLVESGGDLVKPGGSLKLPCAASGFTVSTYAMSWIRQTPEKRLEWVATISSGGSYTYYPDNVKGRFTISRDIAKNTLYLQMSSLRSEDTAMYYCARHPPTVVAGDAMDYWGQGTSVTVSSAKTTPPSVYPLAPGSSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSTWPSETVTCNVAHPASSTKVDKKIVPR', 'QVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLEWMGWINPNSGGTNYAQKFQGRVTMTRDTSISTAYMELSRLRSDDTAVYYCAREVMVRGALPPYGMDVWGQGTTVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKSC', 'EVQLLESGGGLVQPGGSLRLSAAASGFTFSTFSMNWVRQAPGKGLEWVSYISRTSKTIYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYVARGRFFDYWGQGTLVTVS', 'QSVEESGGGLVTPGTPLTLTCTVSGIDLSRYAMSWVRQAPGKGLEWIGIFGSLGGIFYASWAKGRFTISKTSPTTVDLKITSPTTEDTATYFCARMPYTTDRDFWGPGTLVTVSSASTKGPSVFPLAPGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEP', 'EVKLQESGPGKLQPSQTLSLTCSFSGFSLTTSGIGVGWIRQPSGKGLEWLAHIWWSASKYYNTALKSRLTISKDTSNNQVFLKIASVDTADTATYYCARAYYGNYGGYYFDYWGQGTTLTVSSAKTTAPSVYPLAPVCGDTTGSSVTLGCLVKGYFPEPVTLTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVTSSTWPSQSITCNVAHPASSTKVDKKIEPRGPT', 'QLQQSGAEVKKPGSSVKVSCKASGGTFSSYAISWVRQAPGQGLEWMGGIIPTFGTANYAQKFQGRVTITADESTSTAYMELSSLRSEDTAVYYCAQGPIVGAPTDYWGKGTLVTVSSASTKGPSVFPLAPSGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSTQTYICNVNHKPSNTKVDKRV', 'QLQLQESGPGLVKPSETLSLTCTVSGASISANSYYGVWVRQSPGKGLEWVGSIAYRGNSNSGSTYYNPSLKSRATVSVDSSKNQVSLRLTSVTAADTALYYCARRQLLDDGTGYQWAAFDVWGQGTMVTVSSASTKGPSVFPLAPSSGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPK', 'EVQLVQSGPEVKKPGTSVKVSCKASGFTFMSSAVQWVRQARGQRLEWIGWIVIGSGNTNYAQKFQERVTITRDMSTSTAYMELSSLRSEDTAVYYCAAPYCSSISCNDGFDIWGQGTMVTVSSASTKGPSVFPLAPSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEP', 'EVQLLESGGGLVQPGGSLKLSCAASGFAVNNYPMNWVRQAPGKGLEWVSSIIGSGSRASYADSVKGRFTISRDNGKDIVYLQMNNLRADDTALYYCVKDSSTAWWDKPAASEFDFWGQGTMVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPK', 'VQLVQSGAEVKKPGSSVKVSCKASGGTLSSYGISWVRQAPGQGLEWLGGSIPILGTSVYAQKFQGRVTMTADESTSTAHMELSSLRFDDTAIYYCAGVREGMAAISGKNAFDIWGQGTMVTVSSASTKGPSVFPLAPSGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPK', 'QVHLVQSGSELKKPGASVKVSCKASGYSFSRYGIKWVRQAPGQGLEWMGWINTRSGVPAYAQGFTGRFVFSLDTSVDTAFLEISSLKTEDTGIYYCATRPPRFYDKTEYWEDGFDVWGRGTLVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPK', 'DVKLVESGGGLVQPGGSRKLSCAASGFTFSSFGMHWVRQAPEKGLEWVAYISSGSSTIYYADTVKGRFTISRDNPKNTLFLQMTSLRSEDTAMYYCARGDYYGSRGAYWGQGTLVTVSAKTTAPSVYPLAPVCGDTTGSSVTLGCLVKGYFPEPVTLTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVTSSTWPSQSITCNVAHPASSTKVDKKIEPRG', 'DVQLQQSGPGLVAPSQSLSITCTVSGFSLTDYGVNWVRQSPGKGLEWLGVIWGDGITDYNSALKSRLSVTKDNSKSQVFLKMNSLQSGDSARYYCVTGLFDYWGQGTTLTVSS', 'DVQLQESGPGLVKPSQSLSLTCTVTGYSITSDYAWNWIRQFPGNKLEWMGYITYSGTTSYNPSLKSRISISRDTSKNQFFMQLNSVTTEDTGTFYCTRGNGDWGQGTTLTVSSAKTTPPSVYPLAPGSAAQTNSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSPRPSETVTCNVAHPASSTKVDKKI', 'QVQLVQSGAEVQKPGASVKVSCKASGYTFASYDINWVRQATGQGLEWMGWMNPKTGNTGYAQKFQGRVTLTRNTSISTAYMELTSLRSEDTAVYYCATYRIIAAVGYRYFQYWGQGTLVTVSSASTKGPSVFPLAPSSGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPK', 'EVQLVQSGAEVKRPGESLKISCKTSGYSFTSYWISWVRQMPGKGLEWMGAIDPSDSDTRYSPSFQGQVTISADKSISTAYLQWSSLKASDSATYYCAKEGIAARSLDVWGRGVLVTVSSASTKGPSVFPLAPSSSESTAALGCLVKDYFPEPVTVSWNSGSLTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYVCNVNHKPSNTKVDKRVE', 'VQLVESGGGLVQPGGSLRLSCAASGFNFYYSSIHWVRQAPGKGLEWVASISSYYGSTSYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCARETYYTEFSWSYSWGLDYWGQGTLVTVSSASTKGPSVFPLAPSSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKSC', 'EVQLVESGPEVKKPGTSVKVSCKASGFSFSMSAMQWVRRARGQRLEWIGWIVPGSGNANYAQKFQERVTITRDESTNTGYMELSSLRSEDTAVYYCAAPHCNKTNCYDAFDIWGQGTMVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPK', 'EVQLVQSGAEVKKPGESLRISCKGSGYSFSTYWISWVRQMPGKGLEWMGKIYPGDSYTNYSPSFQGQVTISADKSISTAYLQWSSLKASDTAMYYCARGYGIFDYWGQGTLVTVSSASTKGPSVFPLAPTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPK', 'VQLQESGPRLVKPSETLSLTCTVSGGSTSSYFWNWIRQPPGKGLEWIGYIYGSGSADYNPSLKSRVTISIDTSKTQFSLKLTSVTAADTAVYYCARSGFCSDDACYRRGSWFDPWGQGTLVTVSSASTKGPSVFPLAPSGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPK', 'QVQLVESGPGRVKPSQTLSLTCTVSGDSINSGINYWNWIRQPAGKELEWIGRIFTSGTTHYNPSLKSRVTISVDRSKNEFSLTLNSVTAADTAVYFCGRGGTDDYVDYWGQGTLVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPKSC', 'EVQLQESGPSLVKPSQTLSLTCSVTGEPITSGFWDWIRKFPGNKLEFMGYIRYGGGTYYNPSLKSPISITRDTSKNHYYLQLNSVVTEDTATYYCARSRDYYGSSGFAFWGEGTLVTVSAAKTTPPSVYPLAPGCGDTTGSSVTLGCLVKGYFPESVTVTWNSGSLSSSVHTFPALLQSGLYTMSSSVTVPSSTWPSQTVTCSVAHPASSTTVDKKLE', 'VQLVESGGGLVKPGGSLRLSCAASGFTFSSYSMSWVRQAPGKGLEWVSSISRSTPYIYYADSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARDLWSPDSNYYDQSAFDIWGQGTMVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEP', 'QVQLQHSGGGLEQPGGSLRISCAASGFTFNTNDMSWVRQAPGKGLQWVSTIIGIDDTTHYADSVRGRFTVSRDTSKNMVYLQMNSLRVEDTALYYCVKNSGIYSFWGQGTLVTVSSASTKGPSVFPLAPSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPK', 'QQLQESGPGLVKPSETLSLTCTVTGFSLSSYTVNWVRQPAGKGLEWIGYISYGGSAYYASWANGRFTISKDSSKNQVSLKLSSVTAADTAVYFCARHMQVGGAPTGSMAAFDPWGPGTLVTVSSASTKGPSVFPLAPSTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEP'], 'H_target_reg': tensor([[ 0.6957, -1.4832,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.9357, -0.9904, -1.2494,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4179, -0.6355,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 1.0715, -0.2516,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.3773, -0.5673, -1.0719,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.6580, -2.0545,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), 'H_target_bin': tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32), 'H_mask': tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]]), 'L_seq': ['DIVMTQSHKFMSTSVGDRVSITCKASQVGTALAWYQQKPGQSPKLLIYWASTRHTGVPDRFTGSGSGTDFTLTISNVQSEDLSDYFCQQYSSYPTFGGGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSETDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNR', 'VMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKLLIQAASTLQSGVPSRFSGSGSGTEFTLTISSLQPEDFATYYCQQLNSYRYTFGQGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC', 'DIQLTQSPSFLSASVGDRVTITCKASQSVDYSGDSYLNWYQQKPGKAPKLLIYDASNLVSGVPSRFSGSGSGTEFTLTISSLQPEDFATYYCQQSTENPWTFGGGTKLEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGE', 'EVVMTQSPATLSVSPGEGATLSCRASQSVNTNVAWYQQKPGQAPRLLIYGASTRATGIPARFSGSGSGTEFTLTISTLQSEDFAVYYCQQYSNWPPITFGQGTRLEIKRTVAAPSVFIFPPTASVVCLLNNFYPRENSQESVTEQDSKDSTYSLSSTLT', 'DIQMTQSPASLPASPEEIVTITCQASQDIGNWLSWYQQKPGKSPQLLIYGATSLADGVPSRFSASRSGTQYSLKISRLQVEDFGIFYCLQGQSTPYTFGAGTKLELKRTDAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRNE', 'SELTQDPAVSVALGQTVRITCQGDDSYYGWYQQKPGQAPVTVIYGNDNRPSGIPDRFSGSSSGNTASLTITGAQAEDEADYYCGAYDSSGGGGIFGGGTKLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAP', 'DVLLTQTPLSLPVNLGDQASISCRSSQTILHSDGYTYLEWYLQRPGQSPKLLIYRVYKRFSGIPDRFRGSGSGMDFTLTISGVEAEDLGIYYCFQGSYVPRTFGGGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRNE', 'DVLMTQTPLSLPVSLGDQASISCRSSQSLVHSDGNTYLEWYLQKPGQSPNLLIYKLSNRFSGVPDRFSGSGSGTDFTLKISRVEAEDLGVYYCFQGSHVPPTFGGGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRN', 'EIVLTQSPATLSLSPGERATLSCRASQSVSSYLAWYQQKPGQAPRLLIYDASNRATGIPARFSGSGSGTDFTLTISSLEPEDFAVYYCQQRSNWPPVTFGGGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNR', 'IQMTQSPSSLSASVGDRVTITVRASQSISSYLNWYQQKPGEAPKLLIYSASVLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYAQQSVMIPMTFGQGTKVE', 'DIVMTQTPSSTSAAVGGTVTITCQASQSVANNNYLKWYQQKRGQPPKQLIYSVSTLASGVPSRFKGSGSGTQFTLTISDLEADDAATYYCSGYFNNNIGAFGGGTKLEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGE', 'DIVMTQSPASLAVSLGQRATISCRASQSVSTSSYSYMNWYQQKPGQPPKLLIKYASNLESGVPARFSGSGSGTDFTLNIHPLEEEDTATYYCQHSWEIPWTFGGGTKVEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRNEC', 'SYVLTQPPSASGTPGQRVAISCSGSNSNIGSNTVHWYQQLPGAAPKLLIYSNNQRPSGVPDRFSGSNSGTSASLAISRLQSEDEADYYCAAWDDSLNGVVFGGGTKVTVLQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEVEKTVAPTE', 'QSVLTQPPSVSEAPRQTVTISCSGNSSNIGRYPVNWYQQLPGKAPKLLIYSDNLRFSGVPDRFSGSKSGTTASLAIRDLLSEDEADYYCSTWDDTLEGWVFGGGTKVTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPTE', 'EIVLTQSPGTLSLSPGERATLSCRASQSVSSSYLAWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQHYGSSRGWTFGQGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRG', 'QLVLTQSPSASASLGASVKLTCTLNSGNTNFAVAWHQQQAGKGPRYLMTINSDGRQSRGDGIPDRFSGSTSGADRYLTISSLHFEDEGDYYCQAWTADLHVFGPGTRVAVVGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPT', 'DIQMTQSPSSLSASVGDRVTITCRASQGISNYLAWYQQKPGKVPKLLIYAASTLQSGVPSRFSGSGYGTEFTLTISSLQPEDVATYYCQQHDNLPLTFGGGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRG', 'SVLTQPPSASGTPGQSVNISCSGSSSNIGNSYVYWYQQLPGTAPKLLIYRNNRRPSGVPDRFSGSKSDTSASLAISGLRSEDEADYYCATWDDSLSGRLFGGGTKLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAP', 'QIQMTQSPSSLSASLGERVSLTCRASQEISGYLSWLQQKPDGTIKRLIYAASTLDSGVPKRFSGSRSGSDYSLTISSLESEDFADYYCLQYASSPYTFGGGTKLEILRGGAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRNEC', 'DAVVTQESALTTSPGETVTLTCRSSTGAVTTSNYASWVQEKPDHLFTGLIGGTNNRAPGVPARFSGSLIGDKAALTITGAQTEDEAIYFCALWYSNHWVFGGGTKLTVLGGGGGS', 'DIVLTQSPSSLAVSLGQRATISCRASQSVSTSSFRYMHWYQQKPGQPPRLLIKYASNLESGVPARFSGSGSGTDFTLNIHPVEEEDTATYYCQHSWEIPYTFGGGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRNE', 'DIQLTQSPSSLSASVGDSVTITCRASQGFGNYLAWYQQRPGKVPEVLIYAATTLQSGVPSRFSGSGSGTDFTLTISSLQPEDVATYYCQKYNSAPFTFGQGTRLEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGE', 'SYELTQPPSVSVSPGQTARITCSGDALPKKYAYWFQQKPGQSPVLIIYEDSKRPSGIPERFSGSSSGTVATLTISGAQVEDEADYYCYSTDSSGYHGLFGGGTRLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVEVAWKADGSAVNAGVETTKPSKQSNNKYAASSYLSLTSDQWKSHKSYSCQVTHEGSTVEKTVAPA', 'IQMTQSPSSLSASVGDRVTITCRASQSVSSAVAWYQQKPGKAPKLLIYSASSLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQSSIVWEPITFGQGTKVEIKRTVAAPSVFIFPPSDSQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC', 'AIRMTQSPGTLSLSPGERATLSCRASQSVRSSYLAWYQQKPGQAPRLLIYGASTRATGIPDRFSGSGSGTDFILTINRLEPEDLAVYYCQQFGSSPWTFGQGTKVDIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNR', 'SYELTQPPSVSVSPGQTASITCSGDNIGDQYAHWYQQKPGQSPVLVIYQDKNRPSGIPERFSGSNSGNTATLTISGTQAMDEADYYCATYTGFGSLAVFGGGTKLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAP', 'DIQMTQSPSSLSASVGDRVTITCRASQSIDNYLNWYQQKPGKAPKLLIYAASGLQSGVPSRFSGSGSGTEFTLTVSSLHPEDFATYYCQQSYSTLTWTFGQGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGE', 'AIQMTQSPSTLSASVGDRVTITCRASQDINSWLAWYQQKPGKAPKLLIYDASSLHSGVPTRFSGSGSGTEFTLTISSLQPDDFASYYCQQYKSYRTFGRGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRG', 'DIQMSQSSSSFSVSLGDRVTITCKASEDIYSRLAWYQQKPGNAPRLLISGATSLETWVPSRFSGSDSGKDYTLSITSLQTEDVATYFCQQYWSPPPTFGGGTKLEIKRADAAPTVSIFPPSSEQLTSGGASVVCFLNNFYPKDINVKWKIDGSERQNGVLNSWTDQDSKDSTYSMSSTLTLTKDEYERHNSYTCEATHKTSTSPIVKSFNRNEC', 'SELTQDPAVSVALGQTVRITCQGDSLRSNYASWYQQKPGQAPLLVIYGKNYRPSGIPDRFSGSYSGNTASLTISGAQAEDEADYYCNSRDSSGDHPVVFGGGTNLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPT', 'DIQMTQSPATLSVSPGETVTLSCRASQSVRTNVAWYRHKAGQAPMILVSGASTRASGAPARFSGSGYGTEFTLTITSLQSEDFAVYYCLQYNTWPRTFGQGTKVEVKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNR', 'EAVLTQSPGTLSLSPGERATLSCQSSQSVYNNNYLSWFQQKPGQPPRLLIYGASTLTSGVPDRFSGSGSGTDFTLTISRLEPEDFAVYYCAGGYSGSSDKYAFGGGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGE'], 'L_target_reg': tensor([[-1.4848,  0.0000,  0.6865,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.2333,  0.0000, -0.3079,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-2.6970,  0.0000, -2.1811,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.5284, -0.6151,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-2.4451,  0.0000, -2.0631,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.5481,  0.0000,  0.8693,  ...,  0.0000,  0.0000,  0.0000]]), 'L_target_bin': tensor([[0, 0, 1,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0]], dtype=torch.int32), 'L_mask': tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])}\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(test_dataloader):\n",
    "    print(batch)\n",
    "    if idx == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the propostion of pos/neg class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### there are about 80% of negative class vs 20% of positive class  , hence 4:1 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "propotion of position and negative class:  0.09087559688180555 0.9091244031181944\n",
      "ratio of position to negative class:  10.00405427103404\n",
      "propotion of position and negative class:  0.08837646378487783 0.9116235362151222\n",
      "ratio of position to negative class:  10.315229838050056\n",
      "propotion of position and negative class:  0.09189772296568413 0.9081022770343159\n",
      "ratio of position to negative class:  9.881662436548224\n"
     ]
    }
   ],
   "source": [
    "sum_one = train_dataset.data['Hchain_count_positive'].sum()\n",
    "sum_zero = train_dataset.data['Hchain_count_negative'].sum()\n",
    "total = train_dataset.data['Hchain_len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)\n",
    "\n",
    "sum_one = valid_dataset.data['Hchain_count_positive'].sum()\n",
    "sum_zero = valid_dataset.data['Hchain_count_negative'].sum()\n",
    "total = valid_dataset.data['Hchain_len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)\n",
    "\n",
    "sum_one = test_dataset.data['Hchain_count_positive'].sum()\n",
    "sum_zero = test_dataset.data['Hchain_count_negative'].sum()\n",
    "total = test_dataset.data['Hchain_len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "propotion of position and negative class:  0.05469640667558992 0.94530359332441\n",
      "ratio of position to negative class:  17.282736669176536\n",
      "propotion of position and negative class:  0.05594240179772623 0.9440575982022738\n",
      "ratio of position to negative class:  16.875528541226217\n",
      "propotion of position and negative class:  0.054230682755002625 0.9457693172449974\n",
      "ratio of position to negative class:  17.43974571586512\n"
     ]
    }
   ],
   "source": [
    "sum_one = train_dataset.data['Lchain_count_positive'].sum()\n",
    "sum_zero = train_dataset.data['Lchain_count_negative'].sum()\n",
    "total = train_dataset.data['Lchain_len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)\n",
    "\n",
    "sum_one = valid_dataset.data['Lchain_count_positive'].sum()\n",
    "sum_zero = valid_dataset.data['Lchain_count_negative'].sum()\n",
    "total = valid_dataset.data['Lchain_len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)\n",
    "\n",
    "sum_one = test_dataset.data['Lchain_count_positive'].sum()\n",
    "sum_zero = test_dataset.data['Lchain_count_negative'].sum()\n",
    "total = test_dataset.data['Lchain_len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from ./weights/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_best.pt. Resuming from epoch 19\n"
     ]
    }
   ],
   "source": [
    "# ----------------\n",
    "# PARAM\n",
    "# ----------------\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Define the configuration dictionary with all the model parameters\n",
    "\n",
    "# path = \"./weights_antibody/seq/(onehot)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "path = \"./weights_antibody/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path = \"./weights_antibody/seq/(esm35M)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path = \"./weights_antibody/seq/(protbert)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path = \"./weights_antibody/seq/(antiberty)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "\n",
    "# Define the path to the pretrained weight of same model on protein dataset\n",
    "# path_old = \"./weights/seq/(onehot)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "path_old = \"./weights/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path_old = \"./weights/seq/(esm35M)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path_old = \"./weights/seq/(esm)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path_old = \"./weights/seq/(protbert)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"pooling\": False,\n",
    "    \"antibody\": True,\n",
    "    # \"use_local\": False,\n",
    "    \"use_local\": True,\n",
    "    # \"use_global\": False,\n",
    "    \"use_global\": True,\n",
    "    \"num_localextractor_block\": 3,\n",
    "    \"input_dim\": 700,\n",
    "    \"output_dim\": 700,\n",
    "    \"in_channel\": 28,\n",
    "    \"out_channel\": 256,\n",
    "    \"kernel_size\": 23,\n",
    "    \"dilation\": 1,\n",
    "    \"stride\": 1,\n",
    "    \"rnn_hid_dim\": 128,\n",
    "    \"rnn_layers\": 1,\n",
    "    \"bidirectional\": True,\n",
    "    \"rnn_dropout\": 0.2,\n",
    "    \"attention_heads\": 4,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"nb_epochs\": 20,\n",
    "    \"encode_mode\" : 'onehot_meiler'\n",
    "}\n",
    "\n",
    "# with open(path_old+'config.json', 'r') as json_file:\n",
    "#     config = json.load(json_file)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = Aggrepred(config)\n",
    "model = model.to(device=device)\n",
    "\n",
    "model\n",
    "\n",
    "# Load the model weights from the checkpoint\n",
    "_, _ = load_model_from_checkpoint(model, path_old + 'model_best.pt', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 3778561\n",
      "Number of non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------\n",
    "#   OPTIMIZER \n",
    "# ----------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "# optimizer = nn.optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "#                                 betas=(0.9, 0.999),\n",
    "#                                 weight_decay=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# LOSS\n",
    "# ----------------\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, lambda_reg=1.0, lambda_bin=1.0, pos_weight=None):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.lambda_bin = lambda_bin\n",
    "        self.mse_loss = nn.MSELoss()  # Regression Loss (MSE)\n",
    "        \n",
    "        if pos_weight is not None:\n",
    "            # Binary Classification Loss (Weighted BCE with logits)\n",
    "            self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "        else:\n",
    "            self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, outputs, regression_targets):\n",
    "        # Calculate regression loss\n",
    "        reg_loss = self.mse_loss(outputs, regression_targets)\n",
    "        \n",
    "        # Calculate binary classification loss\n",
    "        # Convert regression output to binary labels (logits) for classification\n",
    "        binary_targets = (regression_targets> 0).float()\n",
    "        bin_loss = self.bce_loss(outputs, binary_targets)\n",
    "        \n",
    "        # Combined weighted loss\n",
    "        total_loss = self.lambda_reg * reg_loss + self.lambda_bin * bin_loss\n",
    "        return total_loss\n",
    "\n",
    "mse_loss  = nn.MSELoss()\n",
    "# mse_loss  = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# bce_loss = nn.BCELoss()\n",
    "# bce_loss = nn.BCELoss(weight=class_weights)\n",
    "\n",
    "# class_weights = torch.Tensor([1.0, 12.0]).cuda()\n",
    "pos_class_weights = torch.Tensor([4.0]).to(device)\n",
    "weighted_bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_class_weights)\n",
    "\n",
    "\n",
    "loss_fn = CombinedLoss(lambda_reg=0.7, lambda_bin=0.3, pos_weight=17.0)\n",
    "\n",
    "\n",
    "# ----------------\n",
    "def count_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable_params, non_trainable_params\n",
    "\n",
    "trainable, non_trainable = count_parameters(model)\n",
    "print(f\"Number of trainable parameters: {trainable}\")\n",
    "print(f\"Number of non-trainable parameters: {non_trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrepred(\n",
      "  (local_extractors): ModuleList(\n",
      "    (0): LocalExtractorBlock(\n",
      "      (conv): Conv1d(28, 256, kernel_size=(23,), stride=(1,), padding=(11,))\n",
      "      (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1-2): 2 x LocalExtractorBlock(\n",
      "      (conv): Conv1d(256, 256, kernel_size=(23,), stride=(1,), padding=(11,))\n",
      "      (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (residue_map): Linear(in_features=28, out_features=256, bias=True)\n",
      "  (global_extractor): GlobalInformationExtractor(\n",
      "    (att_bilstm): Att_BiLSTM(\n",
      "      (lstm): LSTM(28, 128, batch_first=True, bidirectional=True)\n",
      "      (attention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "    (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (reg_layer): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.1)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes}m {seconds} s\" if minutes>0 else f\"{seconds} s\"\n",
    "\n",
    "def train_epoch(model, optimizer, dataloader, encode_mode='onehot_meiler', device = 'cuda', printEvery=100):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    count_iter = 0\n",
    "    start_time = time.time()\n",
    "    epoch_start_time = start_time\n",
    "    batch_size = dataloader.batch_size\n",
    "    printEvery = printEvery // batch_size if batch_size else 100  # Adjust printEvery based on batch size\n",
    "\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    esm_model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    esm_model = esm_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    protbert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "    protbert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to('cuda')\n",
    "    \n",
    "    antiberty_model = AntiBERTyRunner()\n",
    "\n",
    "    with tqdm(total=len(dataloader), desc='Training', unit='batch') as pbar:\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "                 \n",
    "            batch_H_sequences = batch['H_seq']\n",
    "            batch_L_sequences = batch['L_seq']\n",
    "\n",
    "            ## different encoding here\n",
    "            if encode_mode == 'esm':\n",
    "                Hchain_x = embed_esm_batch(batch_H_sequences,  esm_model, alphabet).to(device)\n",
    "                Lchain_x = embed_esm_batch(batch_L_sequences,  esm_model, alphabet).to(device)\n",
    "                Hchain_x   = F.pad(Hchain_x, (0, 0, 0, max(450 - Hchain_x.size(1), 0)))\n",
    "                Lchain_x   = F.pad(Lchain_x, (0, 0, 0, max(250 - Lchain_x.size(1), 0)))\n",
    "            \n",
    "            elif encode_mode == 'protbert':\n",
    "                Hchain_x = embed_protbert_batch(batch_H_sequences,  protbert_model, protbert_tokenizer).to(device)\n",
    "                Lchain_x = embed_protbert_batch(batch_L_sequences,  protbert_model, protbert_tokenizer).to(device)\n",
    "                Hchain_x   = F.pad(Hchain_x, (0, 0, 0, max(450 - Hchain_x.size(1), 0)))\n",
    "                Lchain_x   = F.pad(Lchain_x, (0, 0, 0, max(250 - Lchain_x.size(1), 0)))\n",
    "            \n",
    "            elif encode_mode == 'antiberty':\n",
    "                Hchain_x = embed_antiberty_batch(batch_H_sequences,  antiberty_model).to(device)\n",
    "                Lchain_x = embed_antiberty_batch(batch_L_sequences,  antiberty_model).to(device)\n",
    "                Hchain_x   = F.pad(Hchain_x, (0, 0, 0, max(450 - Hchain_x.size(1), 0)))\n",
    "                Lchain_x   = F.pad(Lchain_x, (0, 0, 0, max(250 - Lchain_x.size(1), 0)))\n",
    "                 \n",
    "            elif encode_mode == 'onehot':\n",
    "                Hchain_x = onehot_encode_batch(batch_H_sequences, 450).to(device)\n",
    "                Lchain_x = onehot_encode_batch(batch_L_sequences, 250).to(device)\n",
    "            else:\n",
    "                Hchain_x = onehot_meiler_encode_batch(batch_H_sequences, 450).to(device)\n",
    "                Lchain_x = onehot_meiler_encode_batch(batch_L_sequences, 250).to(device)\n",
    "            \n",
    "            x = torch.cat((Hchain_x, Lchain_x), dim=1)\n",
    "\n",
    "\n",
    "            Hchain_mask = batch['H_mask'].to(device)\n",
    "            Lchain_mask = batch['L_mask'].to(device)\n",
    "\n",
    "            masks = torch.cat((Hchain_mask, Lchain_mask ), dim=1)\n",
    "\n",
    "            \n",
    "            ## convert (bsz,max_len) to  (bsz,max_len,1)\n",
    "            H_y_reg = batch['H_target_reg'].unsqueeze(2).float().to(device)\n",
    "            L_y_reg = batch['L_target_reg'].unsqueeze(2).float().to(device)\n",
    "\n",
    "\n",
    "            y_reg = torch.cat((H_y_reg, L_y_reg ), dim=1)\n",
    "            y_reg = clean_output_batch(y_reg, masks)\n",
    "        \n",
    "            ## prediction\n",
    "            final_info, output_reg = model(x, masks)\n",
    "            \n",
    "            #trim out the padded part\n",
    "            output_reg = clean_output_batch(output_reg, masks)\n",
    "            # print(orig_len.sum())\n",
    "            assert len(output_reg)==len(y_reg) , 'reg output {} and target {} not same length'.format(len(output_reg),len(y_reg))\n",
    "            \n",
    "            current_loss = loss_fn(output_reg, y_reg)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            current_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += current_loss.item()\n",
    "            \n",
    "            printEvery = int(1000/x.size(0))\n",
    "            count_iter += 1\n",
    "            if count_iter % printEvery == 0 or idx == len(dataloader) - 1:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                remaining_time = (elapsed_time / count_iter) * (len(dataloader) - count_iter)\n",
    "                print(f\"Iteration: {count_iter}, Time: {format_time(elapsed_time)}, Remaining: {format_time(remaining_time)}, Training Loss: {total_loss / count_iter:.4f}\")\n",
    "                start_time = time.time()\n",
    "            torch.cuda.empty_cache()\n",
    "            pbar.update(1)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"==> Average Training loss: mse ={total_loss / len(dataloader)}\")\n",
    "    print(f\"==> Epoch Training Time: {format_time(epoch_time)}\")\n",
    "    print(f\"================================================================\\n\")\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, encode_mode='onehot_meiler', device= 'cuda', mode='valid'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    predictions = []\n",
    "    targets = []\n",
    "    binary_predictions = []\n",
    "    binary_targets = []\n",
    "    orig_lens = []\n",
    "\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    esm_model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    esm_model = esm_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    protbert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "    protbert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to('cuda')\n",
    "\n",
    "    antiberty_model = AntiBERTyRunner()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(dataloader), unit='batch') as pbar:\n",
    "            for idx, batch in enumerate(dataloader):\n",
    "                    \n",
    "                batch_H_sequences = batch['H_seq']\n",
    "                batch_L_sequences = batch['L_seq']\n",
    "                            \n",
    "\n",
    "                if encode_mode == 'esm':\n",
    "                    Hchain_x = embed_esm_batch(batch_H_sequences,  esm_model, alphabet).to(device)\n",
    "                    Lchain_x = embed_esm_batch(batch_L_sequences,  esm_model, alphabet).to(device)\n",
    "                    H_max_length =  450\n",
    "                    L_max_length = 250\n",
    "                    Hchain_x   = F.pad(Hchain_x, (0, 0, 0, max(H_max_length - Hchain_x.size(1), 0)))\n",
    "                    Lchain_x   = F.pad(Lchain_x, (0, 0, 0, max(L_max_length - Lchain_x.size(1), 0)))\n",
    "                \n",
    "                elif encode_mode == 'protbert':\n",
    "                    Hchain_x = embed_protbert_batch(batch_H_sequences,  protbert_model, protbert_tokenizer).to(device)\n",
    "                    Lchain_x = embed_protbert_batch(batch_L_sequences,  protbert_model, protbert_tokenizer).to(device)\n",
    "                    H_max_length =  450\n",
    "                    L_max_length = 250\n",
    "                    Hchain_x   = F.pad(Hchain_x, (0, 0, 0, max(H_max_length - Hchain_x.size(1), 0)))\n",
    "                    Lchain_x   = F.pad(Lchain_x, (0, 0, 0, max(L_max_length - Lchain_x.size(1), 0)))\n",
    "                    \n",
    "                elif encode_mode == 'antiberty':\n",
    "                    Hchain_x = embed_antiberty_batch(batch_H_sequences,  antiberty_model).to(device)\n",
    "                    Lchain_x = embed_antiberty_batch(batch_L_sequences,  antiberty_model).to(device)\n",
    "                    H_max_length =  450\n",
    "                    L_max_length = 250\n",
    "                    Hchain_x   = F.pad(Hchain_x, (0, 0, 0, max(H_max_length - Hchain_x.size(1), 0)))\n",
    "                    Lchain_x   = F.pad(Lchain_x, (0, 0, 0, max(L_max_length - Lchain_x.size(1), 0)))\n",
    "                    \n",
    "                elif encode_mode == 'onehot':\n",
    "                    Hchain_x = onehot_encode_batch(batch_H_sequences, 450).to(device)\n",
    "                    Lchain_x = onehot_encode_batch(batch_L_sequences, 250).to(device)\n",
    "                else:\n",
    "                    Hchain_x = onehot_meiler_encode_batch(batch_H_sequences, 450).to(device)\n",
    "                    Lchain_x = onehot_meiler_encode_batch(batch_L_sequences, 250).to(device)\n",
    "\n",
    "      \n",
    "                x = torch.cat((Hchain_x, Lchain_x), dim=1)\n",
    "\n",
    "\n",
    "                Hchain_mask = batch['H_mask'].to(device)\n",
    "                Lchain_mask = batch['L_mask'].to(device)\n",
    "\n",
    "                masks = torch.cat((Hchain_mask, Lchain_mask ), dim=1)\n",
    "\n",
    "                # if not config[\"pooling\"]:\n",
    "\n",
    "                ## convert (bsz,max_len) to  (bsz,max_len,1)\n",
    "                H_y_reg = batch['H_target_reg'].unsqueeze(2).float().to(device)\n",
    "                L_y_reg = batch['L_target_reg'].unsqueeze(2).float().to(device)\n",
    "\n",
    "                # Hchain_y_reg = clean_output_batch(Hchain_y_reg, Hchain_mask)\n",
    "                \n",
    "                y_reg = torch.cat((H_y_reg, L_y_reg ), dim=1)\n",
    "                \n",
    "                y_reg = clean_output_batch(y_reg, masks)\n",
    "            \n",
    "                \n",
    "                \n",
    "                ## prediction\n",
    "                final_info, output_reg = model(x, masks)\n",
    "                \n",
    "                #trim out the padded part\n",
    "                output_reg = clean_output_batch(output_reg, masks)\n",
    "                # print(orig_len.sum())\n",
    "                assert len(output_reg)==len(y_reg) , 'reg output {} and target {} not same length'.format(len(output_reg),len(y_reg))\n",
    "                \n",
    "                current_loss = loss_fn(output_reg, y_reg)\n",
    "                total_loss += current_loss.item()\n",
    "\n",
    "                #append to list of all preds\n",
    "                predictions.append(output_reg.cpu().numpy())\n",
    "                targets.append(y_reg.cpu().numpy())\n",
    " \n",
    "                y_bin = (y_reg.cpu().numpy() > 0).astype(int)\n",
    "                out_bin = (output_reg.cpu().numpy() > 0).astype(int)\n",
    "\n",
    "                binary_predictions.append(out_bin)\n",
    "                binary_targets.append(y_bin)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                pbar.update(1)\n",
    "\n",
    "    all_predictions = np.concatenate(predictions, axis=0).reshape(-1)\n",
    "    all_targets = np.concatenate(targets, axis=0).reshape(-1)\n",
    "\n",
    "    print(\"all pred:\",all_predictions)\n",
    "    print(\"all tar:\",all_targets)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_targets, all_predictions)\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "    overall_mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    overall_r2 = r2_score(all_targets, all_predictions)\n",
    "    overall_pcc, _ = pearsonr(all_targets.flatten(), all_predictions.flatten())\n",
    "    overall_spearman, p_value = spearmanr(all_targets, all_predictions)\n",
    "\n",
    "    print(f\"Overall Regression Metrics\")\n",
    "    print(f\"MSE: {overall_mse:.4f}, RMSE: {overall_rmse:.4f}, MAE: {overall_mae:.4f}, R2: {overall_r2:.4f}, PCC: {overall_pcc:.4f}, spear: {overall_spearman:.4f}, P-value: {p_value:.4f}\")\n",
    "    \n",
    "    all_binary_predictions = np.concatenate(binary_predictions, axis=0).reshape(-1)\n",
    "    all_binary_targets = np.concatenate(binary_targets, axis=0).reshape(-1)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_precision = precision_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_recall = recall_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_f1 = f1_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_auc_roc = roc_auc_score(all_binary_targets, all_predictions)\n",
    "    overall_auc_pr = average_precision_score(all_binary_targets, all_predictions)\n",
    "    overall_mcc = matthews_corrcoef(all_binary_targets, all_binary_predictions)\n",
    "    \n",
    "    \n",
    "    print(f\"Overall classification Metrics\")\n",
    "    print(f\"Acc: {overall_accuracy:.4f}, Precision: {overall_precision:.4f}, Recall: {overall_recall:.4f}, F1-Score: {overall_f1:.4f}, AUC-ROC: {overall_auc_roc:.4f}, AUC-PR: {overall_auc_pr:.4f}, MCC: {overall_mcc:.4f}\")  \n",
    "\n",
    "    metrics = {\n",
    "        \"Regression Metrics\": {\n",
    "            \"MSE\": round(float(overall_mse), 4),\n",
    "            \"RMSE\": round(float(overall_rmse), 4),\n",
    "            \"MAE\": round(float(overall_mae), 4),\n",
    "            \"R2\": round(float(overall_r2), 4),\n",
    "            \"PCC\": round(float(overall_pcc), 4)\n",
    "        },\n",
    "        \"Classification Metrics\": {\n",
    "            \"Accuracy\": round(float(overall_accuracy), 4),\n",
    "            \"Precision\": round(float(overall_precision), 4),\n",
    "            \"Recall\": round(float(overall_recall), 4),\n",
    "            \"F1-Score\": round(float(overall_f1), 4),\n",
    "            \"AUC-ROC\": round(float(overall_auc_roc), 4),\n",
    "            \"AUC-PR\": round(float(overall_auc_pr), 4),\n",
    "            \"MCC\": round(float(overall_mcc), 4)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    return total_loss / len(dataloader),metrics, predictions, targets\n",
    "\n",
    "def train_loop(model, optimizer, train_dataloader, valid_dataloader, nb_epochs,  encode_mode='onehot_meiler', device= 'cuda', save_directory='./weights/'):\n",
    "    start_epoch = 1\n",
    "    best_validation_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    # Paths for saving losses and metrics\n",
    "    loss_output_path = os.path.join(save_directory, 'losses.json')\n",
    "    metric_output_path = os.path.join(save_directory, 'metrics.json')\n",
    "    \n",
    "    # Initialize lists for losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "        print(f'Created directory: {save_directory}')\n",
    "\n",
    "    checkpoint_path = os.path.join(save_directory, 'model_last.pt')\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}. Resuming from epoch {start_epoch}')\n",
    "        \n",
    "    else:\n",
    "        print('No checkpoint found. Starting from beginning.')\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    # Load existing losses if available\n",
    "    if os.path.exists(loss_output_path):\n",
    "        with open(loss_output_path, 'r') as json_file:\n",
    "            existing_losses = json.load(json_file)\n",
    "            train_losses = existing_losses.get('train_losses', [])\n",
    "            val_losses = existing_losses.get('val_losses', [])\n",
    "            print(f'Loaded losses from {loss_output_path}.')\n",
    "            print(train_losses)\n",
    "            print(val_losses)\n",
    "\n",
    "    for epoch in range(start_epoch, nb_epochs + 1):\n",
    "        print(\"==================================================================================\")\n",
    "        print(f'                            -----EPOCH {epoch}-----')\n",
    "        print(\"==================================================================================\")\n",
    "        \n",
    "        train_loss = train_epoch(model, optimizer, train_dataloader, encode_mode ,device, printEvery=1000)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        print(\"==========================VALIDATION===============================================\")\n",
    "        val_loss ,metrics, _ , _ = evaluate(model, valid_dataloader,encode_mode, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'==> Epoch {epoch} - Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < best_validation_loss:\n",
    "            early_stopping_counter = 0\n",
    "            best_validation_loss = val_loss\n",
    "            best_model_save_path = os.path.join(save_directory, 'model_best.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'validation_accuracy': val_loss,\n",
    "            }, best_model_save_path)\n",
    "            print('\\n')\n",
    "            print(f'Best model checkpoint saved to: {best_model_save_path}')\n",
    "\n",
    "            # Save metrics of the best model\n",
    "            with open(metric_output_path, 'w') as json_file:\n",
    "                json.dump(metrics, json_file, indent=4)\n",
    "        \n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= 5:\n",
    "                print(\"\\n==> Early stopping triggered. No improvement in validation loss for 3 epochs.\")\n",
    "                break\n",
    "\n",
    "        last_model_save_path = os.path.join(save_directory, 'model_last.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'validation_accuracy': val_loss,\n",
    "        }, last_model_save_path)\n",
    "        print(f'Last epoch model saved to: {last_model_save_path}')\n",
    "\n",
    "        # Save updated losses to the JSON file\n",
    "        losses = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }\n",
    "        with open(loss_output_path, 'w') as json_file:\n",
    "            json.dump(losses, json_file, indent=4)\n",
    "        print(f'Losses updated and saved to: {loss_output_path}')\n",
    "        \n",
    "        print(\"==================================================================================\\n\")\n",
    "    \n",
    "        \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from ./weights_antibody/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_last.pt. Resuming from epoch 20\n",
      "Loaded losses from ./weights_antibody/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/losses.json.\n",
      "[0.4576486242406162, 0.4007444068973447, 0.3910627243695436, 0.384471039345235, 0.3798428854824584, 0.37673885145305114, 0.3735851023668124, 0.37019821670320296, 0.36761892320197304, 0.36561967745239354, 0.36342159575886196, 0.3608956108858556, 0.35994238323635525, 0.35772130886713666, 0.35626638303568336, 0.3550759531833507, 0.3538394382706395, 0.3518247464556753, 0.35061384093614273]\n",
      "[0.3840257633816112, 0.377922537651929, 0.3751929212700237, 0.3652646297758276, 0.36427256194027985, 0.36586505445567047, 0.3608144630085338, 0.3624091094190424, 0.3653991601683877, 0.36567277799953113, 0.3550783856348558, 0.36211435361342, 0.35823058540170843, 0.3521280451254411, 0.35726405815644696, 0.35811895673925226, 0.35231458057056775, 0.35417500138282776, 0.3556548058986664]\n",
      "==================================================================================\n",
      "                            -----EPOCH 20-----\n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Training:  10%|▉         | 8/81 [00:01<00:18,  4.01batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m      3\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(config, json_file, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencode_mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 317\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, train_dataloader, valid_dataloader, nb_epochs, encode_mode, device, save_directory)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m                            -----EPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================================================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 317\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintEvery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==========================VALIDATION===============================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 80\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader, encode_mode, device, printEvery)\u001b[0m\n\u001b[1;32m     77\u001b[0m final_info, output_reg \u001b[38;5;241m=\u001b[39m model(x, masks)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#trim out the padded part\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m output_reg \u001b[38;5;241m=\u001b[39m \u001b[43mclean_output_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# print(orig_len.sum())\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_reg)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_reg) , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg output \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and target \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not same length\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(output_reg),\u001b[38;5;28mlen\u001b[39m(y_reg))\n",
      "File \u001b[0;32m~/AIDRUG-AUDENSIEL/aggrepred/model.py:336\u001b[0m, in \u001b[0;36mclean_output_batch\u001b[0;34m(output_tensor, binary_masks)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Loop over each sequence in the batch\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# Use the binary mask to filter out the padded positions for each sequence\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     cleaned_outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbinary_masks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Concatenate the cleaned outputs from all sequences\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(cleaned_outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(path, exist_ok=True)\n",
    "with open(os.path.join(path, \"config.json\"), 'w') as json_file:\n",
    "    json.dump(config, json_file, indent=4)\n",
    "\n",
    "train_loop(model,optimizer,train_dataloader,valid_dataloader, 50, config['encode_mode'],device,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:01<00:00,  6.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all pred: [-1.8407423  -0.76543653 -1.0598333  ... -2.0413842  -2.2311563\n",
      " -1.5531867 ]\n",
      "all tar: [-1.9357 -0.9904 -1.2494 ... -2.2551 -2.4902 -1.4156]\n",
      "Overall Regression Metrics\n",
      "MSE: 0.1164, RMSE: 0.3411, MAE: 0.2352, R2: 0.8352, PCC: 0.9173, spear: 0.9017, P-value: 0.0000\n",
      "Overall classification Metrics\n",
      "Acc: 0.9468, Precision: 0.5904, Recall: 0.8951, F1-Score: 0.7115, AUC-ROC: 0.9598, AUC-PR: 0.8160, MCC: 0.7015\n"
     ]
    }
   ],
   "source": [
    "val, metric, preds_val, tar_val = evaluate(model,test_dataloader,config[\"encode_mode\"],device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8407423 , -0.76543653, -1.0598333 , ..., -2.0461276 ,\n",
       "       -2.2356448 , -1.559216  ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9357, -0.9904, -1.2494, ..., -1.773 , -1.8248, -1.2426],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_from_checkpoint(model, optimizer, checkpoint_path, device):\n",
    "    \"\"\"\n",
    "    Loads the model and optimizer state from a checkpoint if it exists.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to load the state into.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n",
    "    - checkpoint_path (str): Path to the checkpoint file.\n",
    "    - device (torch.device): Device to which the model should be moved.\n",
    "    \n",
    "    Returns:\n",
    "    - start_epoch (int): The epoch to start training from.\n",
    "    - best_validation_loss (float): The best validation loss recorded in the checkpoint.\n",
    "    \"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}. Resuming from epoch {start_epoch}')\n",
    "        # print(f'Best validation loss: {best_validation_loss}')\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_validation_loss = float('inf')  # Assuming lower is better for validation loss\n",
    "        print('No checkpoint found.')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    return start_epoch, best_validation_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the configuration dictionary with all the model parameters\n",
    "# path = \"./weights/seq/(onehot)_(regloss)_(global_1layer256_4head)/\"\n",
    "\n",
    "# with open(path+'config.json', 'r') as json_file:\n",
    "#     config = json.load(json_file)\n",
    "\n",
    "# # ----------------\n",
    "# #  MODEL \n",
    "# # ----------------\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Loaded checkpoint from ./weights_antibody/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_best.pt. Resuming from epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:01<00:00,  6.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all pred: [-2.056324   -0.97252727 -1.254567   ...  0.47811094  1.0779473\n",
      "  0.16233161]\n",
      "all tar: [-2.1062 -1.1456 -1.4378 ...  0.1882  0.4603  0.0055]\n",
      "Overall Regression Metrics\n",
      "MSE: 0.1166, RMSE: 0.3414, MAE: 0.2384, R2: 0.8349, PCC: 0.9179, spear: 0.9017, P-value: 0.0000\n",
      "Overall classification Metrics\n",
      "Acc: 0.9511, Precision: 0.6168, Recall: 0.8807, F1-Score: 0.7255, AUC-ROC: 0.9579, AUC-PR: 0.8100, MCC: 0.7129\n",
      "Processed model in path: ./weights_antibody/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\n",
      "\n",
      "Loaded checkpoint from ./weights_antibody/seq/(onehot)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_best.pt. Resuming from epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:01<00:00,  9.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all pred: [ 0.38212374 -1.3036753  -0.10528025 ... -2.7338097  -2.9358606\n",
      " -2.9886072 ]\n",
      "all tar: [ 0.0792 -0.8966  0.     ... -2.6129 -2.8245 -2.8537]\n",
      "Overall Regression Metrics\n",
      "MSE: 0.1263, RMSE: 0.3554, MAE: 0.2367, R2: 0.8211, PCC: 0.9157, spear: 0.9043, P-value: 0.0000\n",
      "Overall classification Metrics\n",
      "Acc: 0.9502, Precision: 0.6081, Recall: 0.9006, F1-Score: 0.7260, AUC-ROC: 0.9608, AUC-PR: 0.8232, MCC: 0.7161\n",
      "Processed model in path: ./weights_antibody/seq/(onehot)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\n",
      "\n",
      "Loaded checkpoint from ./weights_antibody/seq/(protbert)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_best.pt. Resuming from epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/11 [00:00<?, ?batch/s]/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:11<00:00,  1.03s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all pred: [-2.3063288  -1.0799348  -1.8330145  ... -1.9021101  -2.154097\n",
      " -0.85817593]\n",
      "all tar: [-2.2782  0.     -2.1869 ... -1.9211 -2.1215 -0.6413]\n",
      "Overall Regression Metrics\n",
      "MSE: 0.1220, RMSE: 0.3492, MAE: 0.2421, R2: 0.8273, PCC: 0.9154, spear: 0.9023, P-value: 0.0000\n",
      "Overall classification Metrics\n",
      "Acc: 0.9498, Precision: 0.6071, Recall: 0.8921, F1-Score: 0.7225, AUC-ROC: 0.9587, AUC-PR: 0.8050, MCC: 0.7116\n",
      "Processed model in path: ./weights_antibody/seq/(protbert)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\n",
      "\n",
      "Loaded checkpoint from ./weights_antibody/seq/(esm35M)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_best.pt. Resuming from epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:47<00:00,  4.29s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all pred: [ 0.6604782  -0.787432   -0.04835248 ... -2.1069932  -2.4169354\n",
      " -1.2268027 ]\n",
      "all tar: [-1.9421 -0.7348 -0.958  ... -2.8083 -2.4804 -2.716 ]\n",
      "Overall Regression Metrics\n",
      "MSE: 0.7229, RMSE: 0.8502, MAE: 0.6242, R2: -0.0237, PCC: 0.5036, spear: 0.4408, P-value: 0.0000\n",
      "Overall classification Metrics\n",
      "Acc: 0.8910, Precision: 0.3356, Recall: 0.4968, F1-Score: 0.4006, AUC-ROC: 0.8175, AUC-PR: 0.3277, MCC: 0.3511\n",
      "Processed model in path: ./weights_antibody/seq/(esm35M)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\n",
      "\n",
      "Loaded checkpoint from ./weights_antibody/seq/(antiberty)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_best.pt. Resuming from epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 11/11 [00:02<00:00,  5.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all pred: [-1.3935404  -0.87559426 -1.4437468  ... -2.500895   -2.3823454\n",
      " -1.0091255 ]\n",
      "all tar: [-1.7325 -1.6625 -2.2042 ... -2.7051 -2.5862 -1.4152]\n",
      "Overall Regression Metrics\n",
      "MSE: 0.1240, RMSE: 0.3522, MAE: 0.2411, R2: 0.8243, PCC: 0.9117, spear: 0.8982, P-value: 0.0000\n",
      "Overall classification Metrics\n",
      "Acc: 0.9540, Precision: 0.6393, Recall: 0.8563, F1-Score: 0.7321, AUC-ROC: 0.9466, AUC-PR: 0.7921, MCC: 0.7165\n",
      "Processed model in path: ./weights_antibody/seq/(antiberty)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# List of model paths\n",
    "model_paths = [\n",
    "    \"./weights_antibody/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \"./weights_antibody/seq/(onehot)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \"./weights_antibody/seq/(protbert)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \"./weights_antibody/seq/(esm35M)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \"./weights_antibody/seq/(antiberty)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \n",
    "]\n",
    "\n",
    "for path in model_paths:\n",
    "    # Load the config for the current model\n",
    "    with open(path + 'config.json', 'r') as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = Aggrepred(config)\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    # Load the model weights from the checkpoint\n",
    "    _, _ = load_model_from_checkpoint(model, optimizer, path + 'model_best.pt', device)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, metrics, preds, tar = evaluate(model, test_dataloader, config['encode_mode'] ,device)\n",
    "\n",
    "    # Save metrics of the best model\n",
    "    with open(path + 'result.json', 'w') as json_file:\n",
    "        json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "    print(f\"Processed model in path: {path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aggrepred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
