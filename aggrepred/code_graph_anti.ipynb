{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "import sys\n",
    "from scipy.spatial.distance import cdist\n",
    "from torch_geometric.data import Data\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import esm\n",
    "top_folder_path = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "sys.path.insert(0, top_folder_path)\n",
    "\n",
    "\n",
    "from aggrepred.utils import *\n",
    "\n",
    "# default values using in training\n",
    "NEIGHBOUR_RADIUS = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(sequence: str, max_length: int = 1000) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    One-hot encode an amino acid sequence\n",
    "\n",
    "    :param sequence:   protein sequence\n",
    "    :param max_length: specify the maximum length for protein sequence to use, it helps to have have size in batches\n",
    "\n",
    "    :return: max_length x num_features tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    seqlen = len(sequence)\n",
    "    use_length = max_length\n",
    "    # use_length = min(seqlen,max_length) #variable to len of seq, if want fix_size like 1024, set it to fix\n",
    "    encoded = torch.zeros((use_length, NUM_AMINOS))\n",
    "    for i in range(min(seqlen, max_length)):\n",
    "        aa = sequence[i]\n",
    "        encoded[i][aa2idx.get(aa, NUM_AMINOS-1)] = 1\n",
    "    return encoded\n",
    "\n",
    "def onehot_encode_batch(sequences: list, max_length: int = 1000) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    One-hot encode an amino acid sequence\n",
    "\n",
    "    :param sequence:   protein sequence\n",
    "    :param max_length: specify the maximum length for protein sequence to use, it helps to have have size in batches\n",
    "\n",
    "    :return: max_length x num_features tensor\n",
    "    \"\"\"\n",
    "    batch_size = len(sequences)\n",
    "    batch_encoded = torch.zeros((batch_size, max_length, NUM_AMINOS))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        batch_encoded[i] = onehot_encode(seq, max_length)\n",
    "    return batch_encoded\n",
    "\n",
    "def onehot_meiler_encode(sequence: str, max_length: int = 1000) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    One-hot encode an amino acid sequence, then concatenate with Meiler features.\n",
    "\n",
    "    :param sequence:   protein sequence\n",
    "    :param max_length: specify the maximum length for protein sequence to use, it helps to have have size in batches\n",
    "\n",
    "    :return: max_length x num_features tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    seqlen = len(sequence)\n",
    "    use_length = max_length\n",
    "    # use_length = min(seqlen,max_length) #variable to len of seq, if want fix_size like 1024, set it to fix\n",
    "    encoded = torch.zeros((use_length, NUM_AMINOS+ NUM_MEILER))\n",
    "    for i in range(min(seqlen, max_length)):\n",
    "        aa = sequence[i]\n",
    "        encoded[i][aa2idx.get(aa, NUM_AMINOS-1)] = 1\n",
    "        encoded[i][-NUM_MEILER:] = MEILER[aa] if aa in MEILER else MEILER[\"X\"]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def onehot_meiler_encode_batch(sequences: list, max_length: int = 1000) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    One-hot encode an amino acid sequence, then concatenate with Meiler features.\n",
    "\n",
    "    :param sequence:   protein sequence\n",
    "    :param max_length: specify the maximum length for protein sequence to use, it helps to have have size in batches\n",
    "\n",
    "    :return: max_length x num_features tensor\n",
    "    \"\"\"\n",
    "    batch_size = len(sequences)\n",
    "    batch_encoded = torch.zeros((batch_size, max_length, NUM_AMINOS+ NUM_MEILER))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        batch_encoded[i] = onehot_meiler_encode(seq, max_length)\n",
    "    return batch_encoded\n",
    "\n",
    "def embed_esm_batch(batch_sequences, model, alphabet, repr_layer='last'):\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    data = [(\"protein\" + str(i), seq) for i, seq in enumerate(batch_sequences)]\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[model.num_layers], return_contacts=False)\n",
    "\n",
    "    # Get the embeddings from the last layer\n",
    "    last_layer = model.num_layers\n",
    "    token_embeddings = results[\"representations\"][last_layer]\n",
    "    \n",
    "    return token_embeddings[:,1:-1,:]\n",
    "\n",
    "def embed_protbert_batch(sequences, model, tokenizer, device='cuda' ):\n",
    "    model.eval()\n",
    "\n",
    "    sequences_w_spaces = [' '.join(list(seq)) for seq in sequences]\n",
    "    processed_sequences = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_w_spaces]\n",
    "\n",
    "    ids = tokenizer.batch_encode_plus(processed_sequences, add_special_tokens=True, pad_to_max_length=True)\n",
    "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_ids=input_ids,attention_mask=attention_mask)[0]\n",
    "\n",
    "    return embedding[:,1:-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------\n",
    "# Helper functions\n",
    "# ----------------\n",
    "\n",
    "# Dictionary to convert 3-letter codes to 1-letter codes\n",
    "AA_3to1 = {\n",
    "    'ALA': 'A',\n",
    "    'ARG': 'R',\n",
    "    'ASN': 'N',\n",
    "    'ASP': 'D',\n",
    "    'CYS': 'C',\n",
    "    'GLN': 'Q',\n",
    "    'GLU': 'E',\n",
    "    'GLY': 'G',\n",
    "    'HIS': 'H',\n",
    "    'ILE': 'I',\n",
    "    'LEU': 'L',\n",
    "    'LYS': 'K',\n",
    "    'MET': 'M',\n",
    "    'PHE': 'F',\n",
    "    'PRO': 'P',\n",
    "    'SER': 'S',\n",
    "    'THR': 'T',\n",
    "    'TRP': 'W',\n",
    "    'TYR': 'Y',\n",
    "    'VAL': 'V'\n",
    "}\n",
    "\n",
    "# Dictionary to convert 1-letter codes to 3-letter codes\n",
    "AA_1to3 = {v: k for k, v in AA_3to1.items()}\n",
    "\n",
    "def get_Calpha_df(df, chain_id=None):\n",
    "    '''\n",
    "    Filters a DataFrame containing PDB data to return only the C-alpha atoms for specified chain IDs.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing PDB data.\n",
    "    chain_id (list): List of chain IDs to filter by. Default is [None], meaning take all.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing only the C-alpha atoms for all(the whole pdb) or the specified chain IDs.\n",
    "    '''\n",
    "    if chain_id is None:\n",
    "        return df[(df[\"Atom_Name\"].str.strip() == \"CA\")].reset_index(drop=True)\n",
    "    else:\n",
    "        out = df[(df[\"Atom_Name\"].str.strip() == \"CA\") & (df[\"Chain\"].isin(chain_id))].reset_index(drop=True)\n",
    "        if len(out) == 0:\n",
    "            raise ValueError(\"No matching chain in the PDB file.\")\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_AA_onehot_features(df,  chain_id=None):\n",
    "    '''\n",
    "    Encodes CDR residues types as one-hot vectors for model input\n",
    "    \n",
    "    :param H_id: heavy chain ID ('None' if not available)\n",
    "    :param L_id: light chain ID ('None' if not available)\n",
    "    :param df: imgt numbered dataframe for specific pdb entry\n",
    "    :returns: tensor (num_CDR_residues, 20) one-hot encoding for each 20 AA types\n",
    "    '''\n",
    "    \n",
    "    # get CDR C-alpha atoms only\n",
    "    df_CDRs = get_Calpha_df(df, chain_id)\n",
    "    df_Calpha = get_Calpha_df(df, chain_id)\n",
    "    df_CDRs = get_Calpha_df(df, chain_id)\n",
    "    \n",
    "    AA_unique_names = get_ordered_AA_3_letter_codes()\n",
    "    AA_name_dict = {name: idx for idx, name in enumerate(AA_unique_names)}\n",
    "    \n",
    "    # nice names to make rest of code more understandable\n",
    "    num_rows = df_Calpha.shape[0]\n",
    "    num_AA = len(AA_unique_names)\n",
    "    \n",
    "    # convert AA name to one-hot encoding\n",
    "    AA_onehot_matrix = np.zeros((num_rows, num_AA))\n",
    "    \n",
    "    # we will only non-zero elements where residues actually exist\n",
    "    df_Calpha_not_null = df_Calpha[~df_Calpha[\"AA\"].isna()]\n",
    "    df_Calpha_not_null_indices = df_Calpha_not_null.index.values\n",
    "    \n",
    "    AA_onehot_matrix[df_Calpha_not_null_indices,\n",
    "                     [AA_name_dict[residue] for residue in df_Calpha_not_null[\"AA\"]]] = 1\n",
    "    \n",
    "    # convert from numpy to tensor\n",
    "    AA_onehot_tensor = torch.tensor(AA_onehot_matrix)\n",
    "    \n",
    "    return AA_onehot_tensor\n",
    "\n",
    "\n",
    "def get_seq_from_df(df, chainID=None):\n",
    "    '''\n",
    "    Get the full ordered amino acid seq for a protein chain\n",
    "    \n",
    "    :param df: imgt numbered dataframe for specific pdb entry\n",
    "    :param chainID: chain ID of protein in pdb file\n",
    "    :return: ordered list of str of all res nums in certain chain\n",
    "    '''\n",
    "    if chainID is None:\n",
    "        df_Calpha_chain_of_interest = get_Calpha_df(df)\n",
    "    else:\n",
    "        df_Calpha_chain_of_interest = df[(df[\"Chain\"]==chainID) & (df[\"Atom_Name\"]==\"CA\")]\n",
    "    \n",
    "    amino_acids_3letter_list = df_Calpha_chain_of_interest[\"AA\"].values.tolist()\n",
    "\n",
    "        # Convert the 3-letter codes to 1-letter codes\n",
    "    amino_acids_1letter_list = [AA_3to1.get(aa, 'X') for aa in amino_acids_3letter_list]\n",
    "    \n",
    "    # Join the list into a single string\n",
    "    sequence = ''.join(amino_acids_1letter_list)\n",
    "\n",
    "    return  sequence\n",
    "\n",
    "def get_bfactor_from_df(df, chainID=None):\n",
    "    '''\n",
    "    Get the full ordered amino acid seq for a protein chain\n",
    "    \n",
    "    :param df: imgt numbered dataframe for specific pdb entry\n",
    "    :param chainID: chain ID of protein in pdb file\n",
    "    :return: ordered list of str of all res nums in certain chain\n",
    "    '''\n",
    "    df_Calpha_chain_of_interest = get_Calpha_df(df,chainID)\n",
    "\n",
    "    # if chainID is None:\n",
    "    #     df_Calpha_chain_of_interest = get_Calpha_df(df)\n",
    "    # else:\n",
    "    #     df_Calpha_chain_of_interest = df[(df[\"Chain\"]==chainID) & (df[\"Atom_Name\"]==\"CA\")]\n",
    "\n",
    "    return  df_Calpha_chain_of_interest[\"bfactor\"].values.astype(float).tolist()\n",
    "\n",
    "def get_coors(df, chain_ids=None):\n",
    "    '''\n",
    "    Get CDR C-alpha atom coordinates\n",
    "    \n",
    "    :param H_id: heavy chain ID ('None' if not available)\n",
    "    :param L_id: light chain ID ('None' if not available)\n",
    "    :param df: imgt numbered dataframe for specific pdb entry\n",
    "    :returns: tensor (num_CDR_residues, 3) with x, y, z coors of each atom\n",
    "    '''\n",
    "    \n",
    "    # get CDR C-alpha atoms only\n",
    "    df_CA = get_Calpha_df(df, chain_ids)\n",
    "    \n",
    "    # ensure coors are numbers\n",
    "    df_CA[\"x\"] = df_CA[\"x\"].astype(float)\n",
    "    df_CA[\"y\"] = df_CA[\"y\"].astype(float)\n",
    "    df_CA[\"z\"] = df_CA[\"z\"].astype(float)\n",
    "\n",
    "    # get coors as tensor\n",
    "    coors = torch.tensor(df_CA[[\"x\", \"y\", \"z\"]].values)\n",
    "\n",
    "    return coors\n",
    "\n",
    "def get_edge_features(df, chain_ids=None, neighbour_radius=NEIGHBOUR_RADIUS):\n",
    "    '''\n",
    "    Get tensor form of adjacency matrix for all CDR C-alpha atoms\n",
    "    \n",
    "    :param H_id: heavy chain ID ('None' if not available)\n",
    "    :param L_id: light chain ID ('None' if not available)\n",
    "    :param df: imgt numbered dataframe for specific pdb entry\n",
    "    :param neighbour_radius: max distance in Angstroms neighbours can be\n",
    "    :returns: tensor (num_CDR_residues, num_CDR_residues, 1) adj matrix \n",
    "    '''\n",
    "    \n",
    "    xyz_arr = get_coors(df, chain_ids).numpy()\n",
    "    \n",
    "    # get distances\n",
    "    dist_matrix = cdist(xyz_arr, xyz_arr, 'euclidean')\n",
    "    dist_tensor = torch.tensor(dist_matrix)\n",
    "    \n",
    "    # create adjacency matrix from distance info\n",
    "    adj_matrix = torch.where(dist_tensor <= neighbour_radius, 1, 0)\n",
    "    \n",
    "    # remove self loops - do I want to do this???  \n",
    "    adj_matrix = adj_matrix.fill_diagonal_(0, wrap=False)\n",
    "    \n",
    "    # adjust dimensions for model input\n",
    "    adj_matrix.unsqueeze_(-1)\n",
    "    \n",
    "    return adj_matrix\n",
    "\n",
    "\n",
    "def get_all_node_features(df, chain_ids=None):\n",
    "    '''\n",
    "    Get tensor features embedding Amino Acid type and corresponding chain\n",
    "    for each C-alpha atom in the CDR\n",
    "    \n",
    "    :param H_id: heavy chain ID ('None' if not available)\n",
    "    :param L_id: light chain ID ('None' if not available)\n",
    "    :param df: imgt numbered dataframe for specific pdb entry\n",
    "    :returns: tensor (num_CDR_residues, 76||26||22) with multi-hot encoding of selection from\n",
    "              AA type (20), chain H/L (2), loop L1/.../H3 (6), and imgt num (54)\n",
    "    '''\n",
    "\n",
    "    return get_AA_onehot_features(df, chain_ids)\n",
    "                        \n",
    "###########################################\n",
    "\n",
    "def adjacency_matrix_to_edge_index(adj_matrix):\n",
    "    \"\"\"\n",
    "    Convert an adjacency matrix to an edge index representation using tensor operations.\n",
    "\n",
    "    Args:\n",
    "        adj_matrix (torch.Tensor): The adjacency matrix.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The edge index representation.\n",
    "    \"\"\"\n",
    "    # Find the indices of the non-zero elements in the adjacency matrix\n",
    "    edge_index = torch.nonzero(adj_matrix, as_tuple=False).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def edge_index_to_adjacency_matrix(edge_index):\n",
    "    \"\"\"\n",
    "    Convert an edge index representation to an adjacency matrix using tensor operations.\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): The edge index representation.\n",
    "        num_nodes (int): The number of nodes in the graph.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The adjacency matrix.\n",
    "    \"\"\"\n",
    "    num_nodes = torch.max(edge_index) + 1\n",
    "    adj_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.long)\n",
    "    adj_matrix[edge_index[0], edge_index[1]] = 1\n",
    "    return adj_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdb2graph(pdb_path,graph_save_path, chain=None,len_cutoff= 500, score_in_bfactor=True):\n",
    "    \n",
    "    # Check if pdb_path exists\n",
    "    if not os.path.exists(pdb_path):\n",
    "        raise FileNotFoundError(f\"The PDB file path {pdb_path} does not exist.\")\n",
    "    \n",
    "    # Check if graph_save_path exists, if not, create the directory if possible\n",
    "    save_dir = os.path.dirname(graph_save_path)\n",
    "    if not os.path.exists(save_dir):\n",
    "        try:\n",
    "            os.makedirs(save_dir)\n",
    "        except Exception as e:\n",
    "            raise OSError(f\"Failed to create directory {save_dir}: {e}\")\n",
    "\n",
    "    pdb_df = format_pdb(pdb_path)\n",
    "\n",
    "    coors = get_coors(pdb_df,chain).float()\n",
    "    coors[coors != coors] = 0  # Replace NaNs with zeros\n",
    "    feats = get_all_node_features(pdb_df,chain).float()\n",
    "    edges = get_edge_features(pdb_df,chain).float()\n",
    "    edge_index = adjacency_matrix_to_edge_index(edges.squeeze(-1))\n",
    "    \n",
    "    if score_in_bfactor:\n",
    "        scores = get_bfactor_from_df(pdb_df,chain)\n",
    "        y = torch.tensor(scores)\n",
    "    else:\n",
    "        y = None\n",
    "    # print(len(y))\n",
    "    # print(edge_index[0][-20:])\n",
    "    # print(edge_index[1][-20:])\n",
    "\n",
    "    # if len(y) > len_cutoff:\n",
    "\n",
    "    #     # print(\"trucate \", len(y) , \" to \", len_cutoff)\n",
    "    #     ## trucate graph to just a specific size (not too big that cause GPU problem such as 2000nodes)\n",
    "    #     feats = feats[:len_cutoff]\n",
    "\n",
    "    #     # 2. Filter edge indices to include only edges between the first 500 nodes\n",
    "    #     mask = (edge_index[0] < len_cutoff) & (edge_index[1] < len_cutoff)\n",
    "    #     edge_index = edge_index[:, mask]\n",
    "\n",
    "    #     coors = coors[:len_cutoff]\n",
    "    #     y = y[:len_cutoff]\n",
    "\n",
    "    # print(len(y))\n",
    "    # print(edge_index[0][-20:])\n",
    "    # print(edge_index[1][-20:])\n",
    "\n",
    "    graph = Data(x=feats, pos=coors, edge_index=edge_index, y=y)\n",
    "    # Save the graph\n",
    "    torch.save(graph, graph_save_path)\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_folder_path  = \"/Users/lyanchhay/Documents/stage/Stage_AIDRUG_2024/main/data/\"\n",
    "# # graph_save_path = \"/Users/lyanchhay/Documents/stage/Stage_AIDRUG_2024/main/data/graph/\"\n",
    "\n",
    "# data_dir  = \"/users/eleves-b/2023/ly-an.chhay/main/data/\"\n",
    "# graph_save_dir = \"/users/eleves-b/2023/ly-an.chhay/main/data/graph/\"\n",
    "\n",
    "\n",
    "# ## old code with all.csv \n",
    "# df = pd.read_csv(data_folder_path+\"csv/all.csv\")\n",
    "# import ast\n",
    "\n",
    "# for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
    "#     code = row[\"code\"]\n",
    "    \n",
    "#     graph_file_path = os.path.join(graph_save_folder, f\"{code}.pt\")\n",
    "#     pdb_path = os.path.join(data_folder_path, \"pdb\", f\"{code}.pdb\")\n",
    "    \n",
    "#     # Skip processing if the graph file already exists\n",
    "#     if os.path.exists(graph_file_path):\n",
    "#         continue\n",
    "    \n",
    "#     _ = process_pdb2graph(pdb_path,graph_file_path,True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 23523/23523 [00:06<00:00, 3557.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# data_folder_path  = \"/Users/lyanchhay/Documents/stage/Stage_AIDRUG_2024/main/data/\"\n",
    "# graph_save_path = \"/Users/lyanchhay/Documents/stage/Stage_AIDRUG_2024/main/data/graph/\"\n",
    "\n",
    "data_dir  = \"/users/eleves-b/2023/ly-an.chhay/main/data/\"\n",
    "pdb_dir = \"/users/eleves-b/2023/ly-an.chhay/main/data/pdb/\"\n",
    "graph_dir = \"/users/eleves-b/2023/ly-an.chhay/main/data/graph/\"\n",
    "\n",
    "df = pd.read_csv(data_dir+\"pisces/data60_fixed_split.csv\")\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
    "    code = row[\"ID\"]\n",
    "    # chain = row.chain\n",
    "    # code = row[\"code\"]\n",
    "    \n",
    "    graph_file_path = os.path.join(graph_dir, f\"{code}.pt\")\n",
    "    pdb_path = pdb_dir+ f\"{code}.pdb\"\n",
    "    \n",
    "    # Skip processing if the graph file already exists\n",
    "    if os.path.exists(graph_file_path):\n",
    "        continue\n",
    "    \n",
    "    _ = process_pdb2graph(pdb_path,graph_file_path)\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.loader import  DataLoader as graphDataLoader\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, df, graph_dir):\n",
    "        self.data_frame = df.copy()\n",
    "        self.codes = self.data_frame['ID'].tolist()\n",
    "        self.graph_dir = graph_dir\n",
    "\n",
    "        # Check if all graph files exist and filter the codes list accordingly\n",
    "        self.codes = [code for code in self.codes if os.path.exists(f\"{self.graph_dir}/{code}.pt\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.codes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code_id = self.codes[idx]\n",
    "        graph_path = f\"{self.graph_dir}/{code_id}.pt\"\n",
    "        graph_data = torch.load(graph_path)\n",
    "        return graph_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = '/users/eleves-b/2023/ly-an.chhay/main/data/csv/all.csv'\n",
    "graph_dir = \"/users/eleves-b/2023/ly-an.chhay/main/data/graph/\"\n",
    "\n",
    "df = pd.read_csv(\"/users/eleves-b/2023/ly-an.chhay/main/data/pisces/data60_fixed_split.csv\")\n",
    "\n",
    "train_dataset = GraphDataset(df[df.split=='train'], graph_dir)\n",
    "valid_dataset = GraphDataset(df[df.split=='valid'], graph_dir)\n",
    "test_dataset = GraphDataset(df[df.split=='test'], graph_dir)\n",
    "\n",
    "train_dataloader = graphDataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_dataloader = graphDataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = graphDataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# # Create a DataLoader\n",
    "# loader = graphDataLoader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18818"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from aggrepred.EGNN import EGNN\n",
    "\n",
    "\n",
    "class EGNN_Model(nn.Module):\n",
    "    '''\n",
    "    Paragraph uses equivariant graph layers with skip connections\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_feats,\n",
    "        edge_dim = 1,\n",
    "        output_dim = 1,\n",
    "        graph_hidden_layer_output_dims = None,\n",
    "        linear_hidden_layer_output_dims = None,\n",
    "        update_coors = False,\n",
    "        dropout = 0.0,\n",
    "        m_dim = 16\n",
    "    ):\n",
    "        super(EGNN_Model, self).__init__()\n",
    "\n",
    "        self.input_dim = num_feats\n",
    "        self.output_dim = output_dim\n",
    "        current_dim = num_feats\n",
    "        \n",
    "        # these will store the different layers of out model\n",
    "        self.graph_layers = nn.ModuleList()\n",
    "        self.linear_layers = nn.ModuleList()\n",
    "        \n",
    "        # model with 1 standard EGNN and single dense layer if no architecture provided\n",
    "        if graph_hidden_layer_output_dims == None: graph_hidden_layer_output_dims = [num_feats]\n",
    "        if linear_hidden_layer_output_dims == None: linear_hidden_layer_output_dims = []\n",
    "        \n",
    "        # graph layers\n",
    "        for hdim in graph_hidden_layer_output_dims:\n",
    "            self.graph_layers.append(EGNN(dim = current_dim,\n",
    "                                          edge_dim = edge_dim,\n",
    "                                          update_coors = update_coors,\n",
    "                                          dropout = dropout,\n",
    "                                          m_dim = m_dim))\n",
    "            current_dim = hdim\n",
    "            \n",
    "        # dense layers\n",
    "        for hdim in linear_hidden_layer_output_dims:\n",
    "            self.linear_layers.append(nn.Linear(in_features = current_dim,\n",
    "                                                out_features = hdim))\n",
    "            current_dim = hdim\n",
    "        \n",
    "        # final layer to get to per-node output\n",
    "        self.linear_layers.append(nn.Linear(in_features = current_dim, out_features = output_dim))\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "    def forward(self, feats, coors, edges, mask=None):\n",
    "\n",
    "        # graph layers\n",
    "        for layer in self.graph_layers:\n",
    "            feats = F.hardtanh(layer(feats, coors, edges, mask))\n",
    "            \n",
    "        # dense layers\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            feats = self.leakyrelu(layer(feats))\n",
    "            # feats = F.hardtanh(layer(feats))\n",
    "            \n",
    "        # output (i.e. prediction)\n",
    "        feats = self.linear_layers[-1](feats)\n",
    "        \n",
    "        return feats\n",
    "    \n",
    "def count_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable_params, non_trainable_params\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, num_feats, graph_hidden_layer_output_dims, linear_hidden_layer_output_dims, heads=4, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Initialize the model with the given parameters, including Transformer-like skip connections and layer normalization.\n",
    "        \n",
    "        Args:\n",
    "        - num_feats (int): Number of input features (dimensionality of the input nodes).\n",
    "        - graph_hidden_layer_output_dims (list of int): List of hidden dimensions for GAT layers.\n",
    "        - linear_hidden_layer_output_dims (list of int): List of hidden dimensions for fully connected layers.\n",
    "        - heads (int): Number of attention heads for the GAT layers. Default is 8.\n",
    "        - dropout (float): Dropout rate applied between layers. Default is 0.6.\n",
    "        \"\"\"\n",
    "        super(GATModel, self).__init__()\n",
    "        \n",
    "        self.gat_layers = torch.nn.ModuleList()\n",
    "        self.layer_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        # First GAT layer (input layer)\n",
    "        self.gat_layers.append(GATConv(num_feats, graph_hidden_layer_output_dims[0], heads=heads))\n",
    "        self.layer_norms.append(LayerNorm(graph_hidden_layer_output_dims[0] * heads))\n",
    "        \n",
    "        # Hidden GAT layers with Transformer-like skip connections and layer normalization\n",
    "        for i in range(1, len(graph_hidden_layer_output_dims)):\n",
    "            self.gat_layers.append(GATConv(graph_hidden_layer_output_dims[i-1] * heads, graph_hidden_layer_output_dims[i], heads=heads))\n",
    "            self.layer_norms.append(LayerNorm(graph_hidden_layer_output_dims[i] * heads))\n",
    "        \n",
    "        # Linear layers for matching dimensions in residual connections\n",
    "        self.match_dim1 = nn.Linear(num_feats, graph_hidden_layer_output_dims[0] * heads)\n",
    "        # self.match_dim2 = nn.Linear(graph_hidden_channels * heads, graph_hidden_channels * heads)\n",
    "\n",
    "        # Fully Connected layers\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        self.fc_layer_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(linear_hidden_layer_output_dims)):\n",
    "            if i == 0:\n",
    "                self.fc_layers.append(torch.nn.Linear(graph_hidden_layer_output_dims[-1] * heads, linear_hidden_layer_output_dims[i]))\n",
    "            else:\n",
    "                self.fc_layers.append(torch.nn.Linear(linear_hidden_layer_output_dims[i-1], linear_hidden_layer_output_dims[i]))\n",
    "            self.fc_layer_norms.append(LayerNorm(linear_hidden_layer_output_dims[i]))\n",
    "        \n",
    "        # Final output layer\n",
    "        self.fc_layers.append(torch.nn.Linear(linear_hidden_layer_output_dims[-1], 1))  # Output is a single value (aggregation score)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x, edge_index = data.x, data.edge_index\n",
    "        x_residual = self.match_dim1(x)\n",
    "\n",
    "        # Pass through GAT layers with Transformer-like skip connections and layer normalization\n",
    "        for i, gat_layer in enumerate(self.gat_layers):\n",
    "            \n",
    "            x = gat_layer(x, edge_index)\n",
    "            x = x_residual + x  # Residual connection\n",
    "            x = self.layer_norms[i](x)  # Layer normalization\n",
    "            x = F.hardtanh(x)\n",
    "\n",
    "            x_residual = x  # Save input for skip connection\n",
    "        \n",
    "        # Pass through Fully Connected layers \n",
    "        for i, fc_layer in enumerate(self.fc_layers[:-1]):\n",
    "            x = fc_layer(x)\n",
    "            x = self.leakyrelu(x)\n",
    "            x = F.dropout(x, p=0.5)\n",
    "     \n",
    "        # Final output layer (no activation)\n",
    "        x = self.fc_layers[-1](x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATModel(\n",
      "  (gat_layers): ModuleList(\n",
      "    (0): GATConv(20, 20, heads=4)\n",
      "    (1-2): 2 x GATConv(80, 20, heads=4)\n",
      "  )\n",
      "  (layer_norms): ModuleList(\n",
      "    (0-2): 3 x LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (match_dim1): Linear(in_features=20, out_features=80, bias=True)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=80, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      "  (fc_layer_norms): ModuleList(\n",
      "    (0-1): 2 x LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Input feature size (number of input features per node, e.g., 20 for one-hot encoding)\n",
    "num_feats = 20\n",
    "\n",
    "# GCN hidden layer dimensions\n",
    "graph_hidden_layer_output_dims = [20, 20, 20]\n",
    "\n",
    "# Fully connected (linear) hidden layer dimensions\n",
    "linear_hidden_layer_output_dims = [10, 10]\n",
    "\n",
    "# Create the model\n",
    "model = GATModel(\n",
    "    num_feats=num_feats,\n",
    "    graph_hidden_layer_output_dims=graph_hidden_layer_output_dims,\n",
    "    linear_hidden_layer_output_dims=linear_hidden_layer_output_dims\n",
    ")\n",
    "\n",
    "# Check the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class GCNModel(torch.nn.Module):\n",
    "#     def __init__(self, num_feats, graph_hidden_layer_output_dims, linear_hidden_layer_output_dims):\n",
    "#         \"\"\"\n",
    "#         Initialize the model with the given parameters.\n",
    "        \n",
    "#         Args:\n",
    "#         - num_feats (int): Number of input features (dimensionality of the input nodes).\n",
    "#         - graph_hidden_layer_output_dims (list of int): List of hidden dimensions for GCN layers.\n",
    "#         - linear_hidden_layer_output_dims (list of int): List of hidden dimensions for fully connected layers.\n",
    "#         \"\"\"\n",
    "#         super(GCNModel, self).__init__()\n",
    "        \n",
    "#         self.gcn_layers = torch.nn.ModuleList()\n",
    "        \n",
    "#         # First GCN layer (input layer)\n",
    "#         self.gcn_layers.append(GCNConv(num_feats, graph_hidden_layer_output_dims[0]))\n",
    "        \n",
    "#         # Hidden GCN layers\n",
    "#         for i in range(1, len(graph_hidden_layer_output_dims)):\n",
    "#             self.gcn_layers.append(GCNConv(graph_hidden_layer_output_dims[i-1], graph_hidden_layer_output_dims[i]))\n",
    "        \n",
    "#         # Fully Connected layers\n",
    "#         self.fc_layers = torch.nn.ModuleList()\n",
    "        \n",
    "#         for i in range(len(linear_hidden_layer_output_dims)):\n",
    "#             if i == 0:\n",
    "#                 self.fc_layers.append(torch.nn.Linear(graph_hidden_layer_output_dims[-1], linear_hidden_layer_output_dims[i]))\n",
    "#             else:\n",
    "#                 self.fc_layers.append(torch.nn.Linear(linear_hidden_layer_output_dims[i-1], linear_hidden_layer_output_dims[i]))\n",
    "        \n",
    "#         # Final output layer\n",
    "#         self.fc_layers.append(torch.nn.Linear(linear_hidden_layer_output_dims[-1], 1))  # Output is a single value (aggregation score)\n",
    "#         self.leakyrelu = F.leaky_relu(0.1)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         # x, edge_index = data.x, data.edge_index\n",
    "         \n",
    "#         # Pass through GCN layers\n",
    "#         for gcn_layer in self.gcn_layers:\n",
    "#             x = gcn_layer(x, edge_index)\n",
    "#             x = self.leakyrelu(x)\n",
    "        \n",
    "#         # Pass through Fully Connected layers\n",
    "#         for fc_layer in self.fc_layers[:-1]:\n",
    "#             x = fc_layer(x)\n",
    "#             x = self.leakyrelu(x)\n",
    "#             x = F.dropout(x, p=0.5)\n",
    "        \n",
    "#         # Final output layer (no activation)\n",
    "#         x = self.fc_layers[-1](x)\n",
    "        \n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input feature size (number of input features per node, e.g., 20 for one-hot encoding)\n",
    "# num_feats = 20\n",
    "\n",
    "# # GCN hidden layer dimensions\n",
    "# graph_hidden_layer_output_dims = [20, 20, 20]\n",
    "\n",
    "# # Fully connected (linear) hidden layer dimensions\n",
    "# linear_hidden_layer_output_dims = [20, 20]\n",
    "\n",
    "# # Create the model\n",
    "# model = GCNModel(\n",
    "#     num_feats=num_feats,\n",
    "#     graph_hidden_layer_output_dims=graph_hidden_layer_output_dims,\n",
    "#     linear_hidden_layer_output_dims=linear_hidden_layer_output_dims\n",
    "# )\n",
    "\n",
    "# # Check the model architecture\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     print(batch)\n",
    "#     break\n",
    "\n",
    "# x , coors, edge_index , batch , y = batch.x , batch.pos, batch.edge_index, batch.batch, batch.y\n",
    "# # convert edge_index to adjacent matrix, as in EGNN take adj_mat\n",
    "# x = x.unsqueeze(0)\n",
    "# coors = coors.unsqueeze(0)\n",
    "# edges = edge_index_to_adjacency_matrix(edge_index).unsqueeze(2).unsqueeze(0)\n",
    "\n",
    "# out = GCNModel(x,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 22147\n",
      "Number of non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "num_feats = 20\n",
    "graph_hidden_layer_output_dims = [20,20,20]\n",
    "linear_hidden_layer_output_dims = [10,10]\n",
    "\n",
    "dummy_model = EGNN_Model(num_feats = num_feats,\n",
    "                       graph_hidden_layer_output_dims = graph_hidden_layer_output_dims,\n",
    "                       linear_hidden_layer_output_dims = linear_hidden_layer_output_dims)\n",
    "\n",
    "\n",
    "trainable, non_trainable = count_parameters(dummy_model)\n",
    "print(f\"Number of trainable parameters: {trainable}\")\n",
    "print(f\"Number of non-trainable parameters: {non_trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061\n",
      "PQQAPYWTHPQRMEKKLHAVPAGNTVKFRCPAAGNPTPTIRWLKDGQAFHGENRIGGIRLRHQHWSLVMESVVPSDRGTYTCLVENAVGSIRYNYLLDVLEEVQLLESGGGLVQPGGSLRLSCAASGFTFSDYYMSWIRQAPGKGLEWVSTISGSGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARLTAYGHVDSWGQGTLVTVSSASTKGPSVFPLAPSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPKSQSVLTQPPSASGTPGQRVTISCSGSSSNIGTNTVNWYQQLPGTAPKLLIYRNYQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSGPHVVFGGGTKLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPTYPQQAPYWTHPQRMEKKLHAVPAGNTVKFRCPAAGNPTPTIRWLKDGQAFHGENRIGGIRLRHQHWSLVMESVVPSDRGTYTCLVENAVGSIRYNYLLDVLEVQLLESGGGLVQPGGSLRLSCAASGFTFSDYYMSWIRQAPGKGLEWVSTISGSGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARLTAYGHVDSWGQGTLVTVSSASTKGPSVFPLAPSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPKSCVLTQPPSASGTPGQRVTISCSGSSSNIGTNTVNWYQQLPGTAPKLLIYRNYQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSGPHVVFGGGTKLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPT\n",
      "torch.Size([429])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(len(batch.seq[0]))\n",
    "    print(batch.seq[0])\n",
    "    print(batch.y.size())\n",
    "    break\n",
    "\n",
    "# x , coors, edge_index , batch , y = batch.x , batch.pos, batch.edge_index, batch.batch, batch.y\n",
    "# # convert edge_index to adjacent matrix, as in EGNN take adj_mat\n",
    "# x = x.unsqueeze(0)\n",
    "# coors = coors.unsqueeze(0)\n",
    "# edges = edge_index_to_adjacency_matrix(edge_index).unsqueeze(2).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"PQQAPYWTHPQRMEKKLHAVPAGNTVKFRCPAAGNPTPTIRWLKDGQAFHGENRIGGIRLRHQHWSLVMESVVPSDRGTYTCLVENAVGSIRYNYLLDVLEEVQLLESGGGLVQPGGSLRLSCAASGFTFSDYYMSWIRQAPGKGLEWVSTISGSGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARLTAYGHVDSWGQGTLVTVSSASTKGPSVFPLAPSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPKSQSVLTQPPSASGTPGQRVTISCSGSSSNIGTNTVNWYQQLPGTAPKLLIYRNYQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSGPHVVFGGGTKLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPTYPQQAPYWTHPQRMEKKLHAVPAGNTVKFRCPAAGNPTPTIRWLKDGQAFHGENRIGGIRLRHQHWSLVMESVVPSDRGTYTCLVENAVGSIRYNYLLDVLEVQLLESGGGLVQPGGSLRLSCAASGFTFSDYYMSWIRQAPGKGLEWVSTISGSGGSTYYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARLTAYGHVDSWGQGTLVTVSSASTKGPSVFPLAPSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKRVEPKSCVLTQPPSASGTPGQRVTISCSGSSSNIGTNTVNWYQQLPGTAPKLLIYRNYQRPSGVPDRFSGSKSGTSASLAISGLRSEDEADYYCAAWDDSLSGPHVVFGGGTKLTVLGQPKAAPSVTLFPPSSEELQANKATLVCLISDFYPGAVTVAWKADSSPVKAGVETTTPSKQSNNKYAASSYLSLTPEQWKSHRSYSCQVTHEGSTVEKTVAPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of x: torch.Size([1, 255, 20])\n",
      "size of coors: torch.Size([1, 255, 3])\n",
      "size of edges: torch.Size([1, 255, 255, 1])\n"
     ]
    }
   ],
   "source": [
    "print('size of x:', x.size())\n",
    "print('size of coors:', coors.size())\n",
    "print('size of edges:', edges.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "./weights_antibody/graph/(onehot)_(3EGNN)/\n",
      "EGNN_Model(\n",
      "  (graph_layers): ModuleList(\n",
      "    (0-2): 3 x EGNN(\n",
      "      (edge_mlp): Sequential(\n",
      "        (0): Linear(in_features=44, out_features=88, bias=True)\n",
      "        (1): Identity()\n",
      "        (2): SiLU()\n",
      "        (3): Linear(in_features=88, out_features=16, bias=True)\n",
      "        (4): SiLU()\n",
      "      )\n",
      "      (node_norm): Identity()\n",
      "      (coors_norm): Identity()\n",
      "      (node_mlp): Sequential(\n",
      "        (0): Linear(in_features=37, out_features=42, bias=True)\n",
      "        (1): Identity()\n",
      "        (2): SiLU()\n",
      "        (3): Linear(in_features=42, out_features=21, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_layers): ModuleList(\n",
      "    (0): Linear(in_features=21, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      "  (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "Number of trainable parameters: 24310\n",
      "Number of non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "# ----------------\n",
    "# PARAM\n",
    "# ----------------\n",
    "\n",
    "\n",
    "# Define the configuration dictionary with all the model parameters\n",
    "path = \"./weights_antibody/graph/(onehot)_(3EGNN)/\"\n",
    "\n",
    "config = {\n",
    "    \"model\": 'EGNN',\n",
    "    \"num_feats\" : 21,\n",
    "    \"graph_hidden_layer_output_dims\" : [21,21,21],\n",
    "    \"linear_hidden_layer_output_dims\" : [20,10],\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"batch_size\": 1,\n",
    "    \"nb_epochs\": 20,\n",
    "    \"encode_mode\" : 'onehot'\n",
    "}\n",
    "\n",
    "\n",
    "# ----------------\n",
    "#  MODEL \n",
    "# ----------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if config['model']=='GCN':\n",
    "    model = GCNModel(num_feats = config[\"num_feats\"],\n",
    "                       graph_hidden_layer_output_dims = config[\"graph_hidden_layer_output_dims\"],\n",
    "                       linear_hidden_layer_output_dims = config[\"linear_hidden_layer_output_dims\"])\n",
    "elif config['model']=='GAT':\n",
    "    model = GATModel(num_feats = config[\"num_feats\"],\n",
    "                       graph_hidden_layer_output_dims = config[\"graph_hidden_layer_output_dims\"],\n",
    "                       linear_hidden_layer_output_dims = config[\"linear_hidden_layer_output_dims\"])\n",
    "else:\n",
    "    model = EGNN_Model(num_feats = config[\"num_feats\"],\n",
    "                       graph_hidden_layer_output_dims = config[\"graph_hidden_layer_output_dims\"],\n",
    "                       linear_hidden_layer_output_dims = config[\"linear_hidden_layer_output_dims\"])\n",
    "\n",
    "\n",
    "\n",
    "# ----------------\n",
    "def count_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable_params, non_trainable_params\n",
    "\n",
    "print(path)\n",
    "print(model)\n",
    "trainable, non_trainable = count_parameters(model)\n",
    "print(f\"Number of trainable parameters: {trainable}\")\n",
    "print(f\"Number of non-trainable parameters: {non_trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "#   OPTIMIZER \n",
    "# ----------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "#                                 betas=(0.9, 0.999),\n",
    "#                                 weight_decay=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, lambda_reg=1.0, lambda_bin=1.0, pos_weight=None):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.lambda_bin = lambda_bin\n",
    "        self.mse_loss = nn.MSELoss()  # Regression Loss (MSE)\n",
    "        \n",
    "        if pos_weight is not None:\n",
    "            # Binary Classification Loss (Weighted BCE with logits)\n",
    "            self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "        else:\n",
    "            self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, outputs, regression_targets):\n",
    "        # Calculate regression loss\n",
    "        reg_loss = self.mse_loss(outputs, regression_targets)\n",
    "        \n",
    "        # Calculate binary classification loss\n",
    "        # Convert regression output to binary labels (logits) for classification\n",
    "        binary_targets = (regression_targets> 0).float()\n",
    "        bin_loss = self.bce_loss(outputs, binary_targets)\n",
    "        \n",
    "        # Combined weighted loss\n",
    "        total_loss = self.lambda_reg * reg_loss + self.lambda_bin * bin_loss\n",
    "        return total_loss\n",
    "\n",
    "combined_loss = CombinedLoss(lambda_reg=0.7, lambda_bin=0.3, pos_weight=4.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = '/users/eleves-b/2023/ly-an.chhay/main/data/csv/all.csv'\n",
    "graph_dir = \"/users/eleves-b/2023/ly-an.chhay/main/data/graph_antibody/\"\n",
    "\n",
    "df = pd.read_csv(\"/users/eleves-b/2023/ly-an.chhay/main/data/pisces/antibody.csv\").sample(frac=0.10, random_state=42)\n",
    "\n",
    "train_dataset = GraphDataset(df[df.split=='train'], graph_dir)\n",
    "valid_dataset = GraphDataset(df[df.split=='valid'], graph_dir)\n",
    "test_dataset = GraphDataset(df[df.split=='test'], graph_dir)\n",
    "\n",
    "train_dataloader = graphDataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_dataloader = graphDataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = graphDataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# if config['encode_mode'] not in ['onehot', 'onehot_meiler']:\n",
    "#     print(\"yes\")\n",
    "#     train_dataset = GraphDataset(df[df.split=='train'].sample(frac=0.10, random_state=42), graph_dir)\n",
    "#     valid_dataset = GraphDataset(df[df.split=='valid'].sample(frac=0.10, random_state=42), graph_dir)\n",
    "#     test_dataset = GraphDataset(df[df.split=='test'].sample(frac=0.10, random_state=42), graph_dir)\n",
    "\n",
    "#     train_dataloader = graphDataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "#     valid_dataloader = graphDataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "#     test_dataloader = graphDataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# else:\n",
    "#     train_dataset = GraphDataset(df[df.split=='train'], graph_dir)\n",
    "#     valid_dataset = GraphDataset(df[df.split=='valid'], graph_dir)\n",
    "#     test_dataset = GraphDataset(df[df.split=='test'], graph_dir)\n",
    "\n",
    "#     train_dataloader = graphDataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "#     valid_dataloader = graphDataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "#     test_dataloader = graphDataLoader(test_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, matthews_corrcoef\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes}m {seconds}s\"\n",
    "\n",
    "def train_epoch(model, optimizer, dataloader,encode_mode='onehot', device= 'cuda', printEvery=50):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    count_iter = 0\n",
    "    start_time = time.time()\n",
    "    epoch_start_time = start_time\n",
    "\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    esm_model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    esm_model = esm_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # protbert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "    # protbert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to('cuda')\n",
    "\n",
    "\n",
    "    with tqdm(total=len(dataloader), desc='Training', unit='batch') as pbar:\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            # x, coors, edge_index, batch, y = batch.x, batch.pos, batch.edge_index, batch.batch, batch.y\n",
    "            batch_sequences, coors, edge_index, batch, y = batch.seq, batch.pos, batch.edge_index, batch.batch, batch.y\n",
    "            \n",
    "            if config['model']== 'EGNN':\n",
    "                ## different encoding here\n",
    "                if encode_mode == 'esm':\n",
    "                    x = embed_esm_batch(batch_sequences, esm_model, alphabet).to(device)\n",
    "                elif encode_mode == 'protbert':\n",
    "                    x = embed_protbert_batch(batch_sequences, protbert_model, protbert_tokenizer).to(device)\n",
    "                elif encode_mode == 'onehot':\n",
    "                    x = onehot_encode_batch(batch_sequences,len(batch_sequences[0])).to(device)\n",
    "                else:\n",
    "                    x = onehot_meiler_encode_batch(batch_sequences,len(batch_sequences[0])).to(device)\n",
    "\n",
    "                \n",
    "\n",
    "                # x = x.unsqueeze(0).to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                coors = coors.unsqueeze(0).to(device)\n",
    "                edges = edge_index_to_adjacency_matrix(edge_index).unsqueeze(2).unsqueeze(0).to(device)\n",
    "\n",
    "                print(x.size())\n",
    "                print(edges.size())\n",
    "                print(coors.size())\n",
    "                print(y.size())\n",
    "\n",
    "\n",
    "                out = model(x, coors, edges).squeeze()\n",
    "            else:\n",
    "                x = x.to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                out = model(x, edge_index).squeeze()\n",
    "\n",
    "            current_loss = combined_loss(out, y.to(device))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            current_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += current_loss.item()\n",
    "            \n",
    "            count_iter += 1\n",
    "            if count_iter % printEvery == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                remaining_time = (elapsed_time / count_iter) * (len(dataloader) - count_iter)\n",
    "                print(f\"Iteration: {count_iter}, Time: {format_time(elapsed_time)}, Remaining: {format_time(remaining_time)}, Training Loss: {total_loss / count_iter:.4f}\")\n",
    "                start_time = time.time()\n",
    "            \n",
    "            #remove cache to save GPU\n",
    "            torch.cuda.empty_cache()\n",
    "            pbar.update(1)\n",
    "            \n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"==> Average Training loss: mse ={total_loss / len(dataloader)}\")\n",
    "    print(f\"==> Epoch Training Time: {format_time(epoch_time)}\")\n",
    "    print(f\"================================================================\\n\")\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader,encode_mode='onehot', device='cuda', mode='valid'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    predictions = []\n",
    "    targets = []\n",
    "    binary_predictions = []\n",
    "    binary_targets = []\n",
    "\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    esm_model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    esm_model = esm_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # protbert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "    # protbert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to('cuda')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            \n",
    "            batch_sequences, coors, edge_index, batch, y = batch.seq, batch.pos, batch.edge_index, batch.batch, batch.y\n",
    "        \n",
    "            if config['model']== 'EGNN':\n",
    "                # x = x.unsqueeze(0).to(device)\n",
    "                ## different encoding here\n",
    "                if encode_mode == 'esm':\n",
    "                    x = embed_esm_batch(batch_sequences, esm_model, alphabet).to(device)\n",
    "                elif encode_mode == 'protbert':\n",
    "                    x = embed_protbert_batch(batch_sequences, protbert_model, protbert_tokenizer).to(device)\n",
    "                elif encode_mode == 'onehot':\n",
    "                    x = onehot_encode_batch(batch_sequences,len(batch_sequences[0])).to(device)\n",
    "                else:\n",
    "                    x = onehot_meiler_encode_batch(batch_sequences,len(batch_sequences[0])).to(device)\n",
    "\n",
    "                edge_index = edge_index.to(device)\n",
    "                coors = coors.unsqueeze(0).to(device)\n",
    "                edges = edge_index_to_adjacency_matrix(edge_index).unsqueeze(2).unsqueeze(0).to(device)\n",
    "                out = model(x, coors, edges).squeeze()\n",
    "            else:\n",
    "                x = x.to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                out = model(x, edge_index).squeeze()\n",
    "\n",
    "            current_loss = combined_loss(out, y.to(device))\n",
    "            # current_loss = weighted_bce_loss(out, (y>0).float().to(device)) + mse_loss(out, y.to(device))\n",
    "            \n",
    "            total_loss += current_loss.item()\n",
    "       \n",
    "\n",
    "            #append to list of all preds\n",
    "            predictions.append(out.cpu().numpy())\n",
    "            targets.append(y.cpu().numpy())\n",
    "            \n",
    "            ## Convert regression targets to binary labels\n",
    "            y_bin = (y.cpu().numpy() > 0).astype(int)\n",
    "            out_bin = (out.cpu().numpy() > 0).astype(int)\n",
    "            \n",
    "            binary_predictions.append(out_bin)\n",
    "            binary_targets.append(y_bin)\n",
    "\n",
    "    # if mode == 'test':\n",
    "    all_predictions = np.concatenate(predictions, axis=0)\n",
    "    all_targets = np.concatenate(targets, axis=0)\n",
    "    all_binary_predictions = np.concatenate(binary_predictions, axis=0)\n",
    "    all_binary_targets = np.concatenate(binary_targets, axis=0)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_mse = mean_squared_error(all_targets, all_predictions)\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "    overall_mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    overall_r2 = r2_score(all_targets, all_predictions)\n",
    "    overall_pcc, _ = pearsonr(all_targets.flatten(), all_predictions.flatten())\n",
    "\n",
    "    # Calculate binary classification metrics\n",
    "    overall_accuracy = accuracy_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_precision = precision_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_recall = recall_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_f1 = f1_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_auc_roc = roc_auc_score(all_binary_targets, all_predictions)\n",
    "    overall_auc_pr = average_precision_score(all_binary_targets, all_predictions)\n",
    "    overall_mcc = matthews_corrcoef(all_binary_targets, all_binary_predictions)\n",
    "\n",
    "    print(f\"Overall Reg Metrics - MSE: {overall_mse:.4f}, RMSE: {overall_rmse:.4f}, MAE: {overall_mae:.4f}, R2: {overall_r2:.4f}, PCC: {overall_pcc:.4f}\")\n",
    "    \n",
    "    print(f\"Overall Classification Metrics - Accuracy: {overall_accuracy:.4f}, Precision: {overall_precision:.4f}, Recall: {overall_recall:.4f}, F1-Score: {overall_f1:.4f}, AUC-ROC: {overall_auc_roc:.4f}, AUC-PR: {overall_auc_pr:.4f}, MCC: {overall_mcc:.4f}\")\n",
    "    metrics = {\n",
    "        \"Regression Metrics\": {\n",
    "            \"MSE\": round(float(overall_mse), 4),\n",
    "            \"RMSE\": round(float(overall_rmse), 4),\n",
    "            \"MAE\": round(float(overall_mae), 4),\n",
    "            \"R2\": round(float(overall_r2), 4),\n",
    "            \"PCC\": round(float(overall_pcc), 4)\n",
    "        },\n",
    "        \"Classification Metrics\": {\n",
    "            \"Accuracy\": round(float(overall_accuracy), 4),\n",
    "            \"Precision\": round(float(overall_precision), 4),\n",
    "            \"Recall\": round(float(overall_recall), 4),\n",
    "            \"F1-Score\": round(float(overall_f1), 4),\n",
    "            \"AUC-ROC\": round(float(overall_auc_roc), 4),\n",
    "            \"AUC-PR\": round(float(overall_auc_pr), 4),\n",
    "            \"MCC\": round(float(overall_mcc), 4)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return total_loss / len(dataloader),metrics, predictions, targets\n",
    "\n",
    "def train_loop(model, optimizer, train_dataloader, valid_dataloader, nb_epochs,encode_mode='onehot_meiler', device= 'cuda', save_directory='./weights/'):\n",
    "    \n",
    "    start_epoch = 1\n",
    "    best_validation_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    # Paths for saving losses and metrics\n",
    "    loss_output_path = os.path.join(save_directory, 'losses.json')\n",
    "    metric_output_path = os.path.join(save_directory, 'metrics.json')\n",
    "    \n",
    "    # Initialize lists for losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "        print(f'Created directory: {save_directory}')\n",
    "\n",
    "    checkpoint_path = os.path.join(save_directory, 'model_last.pt')\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}. Resuming from epoch {start_epoch}')\n",
    "        \n",
    "        # # Load losses from the losses.json file if it exists\n",
    "        # if os.path.exists(loss_output_path):\n",
    "        #     with open(loss_output_path, 'r') as f:\n",
    "        #         losses = json.load(f)\n",
    "        #         train_losses = losses.get('train_losses', [])\n",
    "        #         val_losses = losses.get('val_losses', [])\n",
    "        #     print(f'Loaded losses from {loss_output_path}.')\n",
    "        #     print(train_losses)\n",
    "        #     print(val_losses)\n",
    "        # else:\n",
    "        #     print(f'No losses file found at {loss_output_path}.')\n",
    "\n",
    "    else:\n",
    "        print('No checkpoint found. Starting from beginning.')\n",
    "    \n",
    "    # print(model)\n",
    "    # model.to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    # Load existing losses if available\n",
    "    if os.path.exists(loss_output_path):\n",
    "        with open(loss_output_path, 'r') as json_file:\n",
    "            existing_losses = json.load(json_file)\n",
    "            train_losses = existing_losses.get('train_losses', [])\n",
    "            val_losses = existing_losses.get('val_losses', [])\n",
    "            print(train_losses)\n",
    "            print(val_losses)\n",
    "\n",
    "    for epoch in range(start_epoch, nb_epochs + 1):\n",
    "        print(\"==================================================================================\")\n",
    "        print(f'                            -----EPOCH {epoch}-----')\n",
    "        print(\"==================================================================================\")\n",
    "        \n",
    "        train_loss = train_epoch(model, optimizer, train_dataloader,encode_mode,device, printEvery=1000)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # # **Print Gradients**\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f'Gradient - {name}: {param.grad.norm()}')  # Prints the norm of gradients\n",
    "\n",
    "        print(\"==========================VALIDATION===============================================\")\n",
    "        val_loss ,metrics, _ , _ = evaluate(model, valid_dataloader,encode_mode,device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'==> Epoch {epoch} - Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < best_validation_loss:\n",
    "            early_stopping_counter = 0\n",
    "            best_validation_loss = val_loss\n",
    "            best_model_save_path = os.path.join(save_directory, 'model_best.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'validation_accuracy': val_loss,\n",
    "            }, best_model_save_path)\n",
    "            print('\\n')\n",
    "            print(f'Best model checkpoint saved to: {best_model_save_path}')\n",
    "\n",
    "            # Save metrics of the best model\n",
    "            with open(metric_output_path, 'w') as json_file:\n",
    "                json.dump(metrics, json_file, indent=4)\n",
    "        \n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= 3:\n",
    "                print(\"\\n==> Early stopping triggered. No improvement in validation loss for 3 epochs.\")\n",
    "                break\n",
    "\n",
    "        last_model_save_path = os.path.join(save_directory, 'model_last.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'validation_accuracy': val_loss,\n",
    "        }, last_model_save_path)\n",
    "        print(f'Last epoch model saved to: {last_model_save_path}')\n",
    "        print(\"==================================================================================\\n\")\n",
    "    \n",
    "        # Save updated losses to the JSON file\n",
    "        losses = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }\n",
    "        with open(loss_output_path, 'w') as json_file:\n",
    "            json.dump(losses, json_file, indent=4)\n",
    "        print(f'Losses updated and saved to: {loss_output_path}')\n",
    "        \n",
    "    return\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from ./weights_antibody/graph/(onehot)_(3EGNN)/model_last.pt. Resuming from epoch 13\n",
      "[21.188981015563467, 21.187766279754054, 21.186478816686463, 21.1860033426705, 21.18563679077616, 21.18391943731527, 21.1831734214706, 21.182343698096002, 21.182362777291587, 21.18133555358397, 21.18088679363901, 21.180064271236287]\n",
      "[26.907335754363768, 26.906338964739152, 26.906807603374606, 26.90265687627177, 26.90422487258911, 26.903301119804382, 26.9002626557504, 26.900180587845465, 26.89686845771728, 26.89861907497529, 26.898993732467776, 26.900196242717005]\n",
      "==================================================================================\n",
      "                            -----EPOCH 13-----\n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/261 [00:00<00:30,  8.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 426, 21])\n",
      "torch.Size([1, 426, 426, 1])\n",
      "torch.Size([1, 426, 3])\n",
      "torch.Size([426])\n",
      "torch.Size([1, 428, 21])\n",
      "torch.Size([1, 428, 428, 1])\n",
      "torch.Size([1, 428, 3])\n",
      "torch.Size([428])\n",
      "torch.Size([1, 430, 21])\n",
      "torch.Size([1, 430, 430, 1])\n",
      "torch.Size([1, 430, 3])\n",
      "torch.Size([430])\n",
      "torch.Size([1, 430, 21])\n",
      "torch.Size([1, 430, 430, 1])\n",
      "torch.Size([1, 430, 3])\n",
      "torch.Size([430])\n",
      "torch.Size([1, 427, 21])\n",
      "torch.Size([1, 427, 427, 1])\n",
      "torch.Size([1, 427, 3])\n",
      "torch.Size([427])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 9/261 [00:00<00:09, 27.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 442, 21])\n",
      "torch.Size([1, 442, 442, 1])\n",
      "torch.Size([1, 442, 3])\n",
      "torch.Size([442])\n",
      "torch.Size([1, 444, 21])\n",
      "torch.Size([1, 444, 444, 1])\n",
      "torch.Size([1, 444, 3])\n",
      "torch.Size([444])\n",
      "torch.Size([1, 427, 21])\n",
      "torch.Size([1, 427, 427, 1])\n",
      "torch.Size([1, 427, 3])\n",
      "torch.Size([427])\n",
      "torch.Size([1, 423, 21])\n",
      "torch.Size([1, 423, 423, 1])\n",
      "torch.Size([1, 423, 3])\n",
      "torch.Size([423])\n",
      "torch.Size([1, 429, 21])\n",
      "torch.Size([1, 429, 429, 1])\n",
      "torch.Size([1, 429, 3])\n",
      "torch.Size([429])\n",
      "torch.Size([1, 240, 21])\n",
      "torch.Size([1, 240, 240, 1])\n",
      "torch.Size([1, 240, 3])\n",
      "torch.Size([240])\n",
      "torch.Size([1, 428, 21])\n",
      "torch.Size([1, 428, 428, 1])\n",
      "torch.Size([1, 428, 3])\n",
      "torch.Size([428])\n",
      "torch.Size([1, 433, 21])\n",
      "torch.Size([1, 433, 433, 1])\n",
      "torch.Size([1, 433, 3])\n",
      "torch.Size([433])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 17/261 [00:00<00:07, 33.13batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 454, 21])\n",
      "torch.Size([1, 454, 454, 1])\n",
      "torch.Size([1, 454, 3])\n",
      "torch.Size([454])\n",
      "torch.Size([1, 433, 21])\n",
      "torch.Size([1, 433, 433, 1])\n",
      "torch.Size([1, 433, 3])\n",
      "torch.Size([433])\n",
      "torch.Size([1, 435, 21])\n",
      "torch.Size([1, 435, 435, 1])\n",
      "torch.Size([1, 435, 3])\n",
      "torch.Size([435])\n",
      "torch.Size([1, 227, 21])\n",
      "torch.Size([1, 227, 227, 1])\n",
      "torch.Size([1, 227, 3])\n",
      "torch.Size([227])\n",
      "torch.Size([1, 441, 21])\n",
      "torch.Size([1, 441, 441, 1])\n",
      "torch.Size([1, 441, 3])\n",
      "torch.Size([441])\n",
      "torch.Size([1, 433, 21])\n",
      "torch.Size([1, 433, 433, 1])\n",
      "torch.Size([1, 433, 3])\n",
      "torch.Size([433])\n",
      "torch.Size([1, 433, 21])\n",
      "torch.Size([1, 433, 433, 1])\n",
      "torch.Size([1, 433, 3])\n",
      "torch.Size([433])\n",
      "torch.Size([1, 434, 21])\n",
      "torch.Size([1, 434, 434, 1])\n",
      "torch.Size([1, 434, 3])\n",
      "torch.Size([434])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 25/261 [00:00<00:07, 32.24batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 433, 21])\n",
      "torch.Size([1, 433, 433, 1])\n",
      "torch.Size([1, 433, 3])\n",
      "torch.Size([433])\n",
      "torch.Size([1, 431, 21])\n",
      "torch.Size([1, 431, 431, 1])\n",
      "torch.Size([1, 431, 3])\n",
      "torch.Size([431])\n",
      "torch.Size([1, 437, 21])\n",
      "torch.Size([1, 437, 437, 1])\n",
      "torch.Size([1, 437, 3])\n",
      "torch.Size([437])\n",
      "torch.Size([1, 433, 21])\n",
      "torch.Size([1, 433, 433, 1])\n",
      "torch.Size([1, 433, 3])\n",
      "torch.Size([433])\n",
      "torch.Size([1, 430, 21])\n",
      "torch.Size([1, 430, 430, 1])\n",
      "torch.Size([1, 430, 3])\n",
      "torch.Size([430])\n",
      "torch.Size([1, 427, 21])\n",
      "torch.Size([1, 427, 427, 1])\n",
      "torch.Size([1, 427, 3])\n",
      "torch.Size([427])\n",
      "torch.Size([1, 426, 21])\n",
      "torch.Size([1, 426, 426, 1])\n",
      "torch.Size([1, 426, 3])\n",
      "torch.Size([426])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 33/261 [00:01<00:06, 33.02batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 436, 21])\n",
      "torch.Size([1, 436, 436, 1])\n",
      "torch.Size([1, 436, 3])\n",
      "torch.Size([436])\n",
      "torch.Size([1, 230, 21])\n",
      "torch.Size([1, 230, 230, 1])\n",
      "torch.Size([1, 230, 3])\n",
      "torch.Size([230])\n",
      "torch.Size([1, 434, 21])\n",
      "torch.Size([1, 434, 434, 1])\n",
      "torch.Size([1, 434, 3])\n",
      "torch.Size([434])\n",
      "torch.Size([1, 444, 21])\n",
      "torch.Size([1, 444, 444, 1])\n",
      "torch.Size([1, 444, 3])\n",
      "torch.Size([444])\n",
      "torch.Size([1, 425, 21])\n",
      "torch.Size([1, 425, 425, 1])\n",
      "torch.Size([1, 425, 3])\n",
      "torch.Size([425])\n",
      "torch.Size([1, 424, 21])\n",
      "torch.Size([1, 424, 424, 1])\n",
      "torch.Size([1, 424, 3])\n",
      "torch.Size([424])\n",
      "torch.Size([1, 427, 21])\n",
      "torch.Size([1, 427, 427, 1])\n",
      "torch.Size([1, 427, 3])\n",
      "torch.Size([427])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 41/261 [00:01<00:07, 30.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 439, 21])\n",
      "torch.Size([1, 439, 439, 1])\n",
      "torch.Size([1, 439, 3])\n",
      "torch.Size([439])\n",
      "torch.Size([1, 443, 21])\n",
      "torch.Size([1, 443, 443, 1])\n",
      "torch.Size([1, 443, 3])\n",
      "torch.Size([443])\n",
      "torch.Size([1, 454, 21])\n",
      "torch.Size([1, 454, 454, 1])\n",
      "torch.Size([1, 454, 3])\n",
      "torch.Size([454])\n",
      "torch.Size([1, 424, 21])\n",
      "torch.Size([1, 424, 424, 1])\n",
      "torch.Size([1, 424, 3])\n",
      "torch.Size([424])\n",
      "torch.Size([1, 428, 21])\n",
      "torch.Size([1, 428, 428, 1])\n",
      "torch.Size([1, 428, 3])\n",
      "torch.Size([428])\n",
      "torch.Size([1, 434, 21])\n",
      "torch.Size([1, 434, 434, 1])\n",
      "torch.Size([1, 434, 3])\n",
      "torch.Size([434])\n",
      "torch.Size([1, 435, 21])\n",
      "torch.Size([1, 435, 435, 1])\n",
      "torch.Size([1, 435, 3])\n",
      "torch.Size([435])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 45/261 [00:01<00:06, 30.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 437, 21])\n",
      "torch.Size([1, 437, 437, 1])\n",
      "torch.Size([1, 437, 3])\n",
      "torch.Size([437])\n",
      "torch.Size([1, 437, 21])\n",
      "torch.Size([1, 437, 437, 1])\n",
      "torch.Size([1, 437, 3])\n",
      "torch.Size([437])\n",
      "torch.Size([1, 434, 21])\n",
      "torch.Size([1, 434, 434, 1])\n",
      "torch.Size([1, 434, 3])\n",
      "torch.Size([434])\n",
      "torch.Size([1, 430, 21])\n",
      "torch.Size([1, 430, 430, 1])\n",
      "torch.Size([1, 430, 3])\n",
      "torch.Size([430])\n",
      "torch.Size([1, 424, 21])\n",
      "torch.Size([1, 424, 424, 1])\n",
      "torch.Size([1, 424, 3])\n",
      "torch.Size([424])\n",
      "torch.Size([1, 432, 21])\n",
      "torch.Size([1, 432, 432, 1])\n",
      "torch.Size([1, 432, 3])\n",
      "torch.Size([432])\n",
      "torch.Size([1, 432, 21])\n",
      "torch.Size([1, 432, 432, 1])\n",
      "torch.Size([1, 432, 3])\n",
      "torch.Size([432])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 53/261 [00:01<00:06, 30.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 429, 21])\n",
      "torch.Size([1, 429, 429, 1])\n",
      "torch.Size([1, 429, 3])\n",
      "torch.Size([429])\n",
      "torch.Size([1, 420, 21])\n",
      "torch.Size([1, 420, 420, 1])\n",
      "torch.Size([1, 420, 3])\n",
      "torch.Size([420])\n",
      "torch.Size([1, 439, 21])\n",
      "torch.Size([1, 439, 439, 1])\n",
      "torch.Size([1, 439, 3])\n",
      "torch.Size([439])\n",
      "torch.Size([1, 432, 21])\n",
      "torch.Size([1, 432, 432, 1])\n",
      "torch.Size([1, 432, 3])\n",
      "torch.Size([432])\n",
      "torch.Size([1, 438, 21])\n",
      "torch.Size([1, 438, 438, 1])\n",
      "torch.Size([1, 438, 3])\n",
      "torch.Size([438])\n",
      "torch.Size([1, 426, 21])\n",
      "torch.Size([1, 426, 426, 1])\n",
      "torch.Size([1, 426, 3])\n",
      "torch.Size([426])\n",
      "torch.Size([1, 429, 21])\n",
      "torch.Size([1, 429, 429, 1])\n",
      "torch.Size([1, 429, 3])\n",
      "torch.Size([429])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 61/261 [00:01<00:06, 31.54batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 429, 21])\n",
      "torch.Size([1, 429, 429, 1])\n",
      "torch.Size([1, 429, 3])\n",
      "torch.Size([429])\n",
      "torch.Size([1, 439, 21])\n",
      "torch.Size([1, 439, 439, 1])\n",
      "torch.Size([1, 439, 3])\n",
      "torch.Size([439])\n",
      "torch.Size([1, 422, 21])\n",
      "torch.Size([1, 422, 422, 1])\n",
      "torch.Size([1, 422, 3])\n",
      "torch.Size([422])\n",
      "torch.Size([1, 440, 21])\n",
      "torch.Size([1, 440, 440, 1])\n",
      "torch.Size([1, 440, 3])\n",
      "torch.Size([440])\n",
      "torch.Size([1, 326, 21])\n",
      "torch.Size([1, 326, 326, 1])\n",
      "torch.Size([1, 326, 3])\n",
      "torch.Size([326])\n",
      "torch.Size([1, 425, 21])\n",
      "torch.Size([1, 425, 425, 1])\n",
      "torch.Size([1, 425, 3])\n",
      "torch.Size([425])\n",
      "torch.Size([1, 439, 21])\n",
      "torch.Size([1, 439, 439, 1])\n",
      "torch.Size([1, 439, 3])\n",
      "torch.Size([439])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 65/261 [00:02<00:06, 31.36batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 429, 21])\n",
      "torch.Size([1, 429, 429, 1])\n",
      "torch.Size([1, 429, 3])\n",
      "torch.Size([429])\n",
      "torch.Size([1, 434, 21])\n",
      "torch.Size([1, 434, 434, 1])\n",
      "torch.Size([1, 434, 3])\n",
      "torch.Size([434])\n",
      "torch.Size([1, 441, 21])\n",
      "torch.Size([1, 441, 441, 1])\n",
      "torch.Size([1, 441, 3])\n",
      "torch.Size([441])\n",
      "torch.Size([1, 439, 21])\n",
      "torch.Size([1, 439, 439, 1])\n",
      "torch.Size([1, 439, 3])\n",
      "torch.Size([439])\n",
      "torch.Size([1, 452, 21])\n",
      "torch.Size([1, 452, 452, 1])\n",
      "torch.Size([1, 452, 3])\n",
      "torch.Size([452])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 72/261 [00:02<00:06, 29.44batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 427, 21])\n",
      "torch.Size([1, 427, 427, 1])\n",
      "torch.Size([1, 427, 3])\n",
      "torch.Size([427])\n",
      "torch.Size([1, 433, 21])\n",
      "torch.Size([1, 433, 433, 1])\n",
      "torch.Size([1, 433, 3])\n",
      "torch.Size([433])\n",
      "torch.Size([1, 432, 21])\n",
      "torch.Size([1, 432, 432, 1])\n",
      "torch.Size([1, 432, 3])\n",
      "torch.Size([432])\n",
      "torch.Size([1, 436, 21])\n",
      "torch.Size([1, 436, 436, 1])\n",
      "torch.Size([1, 436, 3])\n",
      "torch.Size([436])\n",
      "torch.Size([1, 436, 21])\n",
      "torch.Size([1, 436, 436, 1])\n",
      "torch.Size([1, 436, 3])\n",
      "torch.Size([436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(config, json_file, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencode_mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[77], line 265\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, train_dataloader, valid_dataloader, nb_epochs, encode_mode, device, save_directory)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m                            -----EPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==================================================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 265\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencode_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintEvery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# # **Print Gradients**\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# for name, param in model.named_parameters():\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m#     if param.grad is not None:\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m#         print(f'Gradient - {name}: {param.grad.norm()}')  # Prints the norm of gradients\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[77], line 84\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader, encode_mode, device, printEvery)\u001b[0m\n\u001b[1;32m     81\u001b[0m             start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;66;03m#remove cache to save GPU\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m epoch_start_time\n",
      "File \u001b[0;32m~/.conda/envs/aggrepred/lib/python3.10/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(path, exist_ok=True)\n",
    "with open(os.path.join(path, \"config.json\"), 'w') as json_file:\n",
    "    json.dump(config, json_file, indent=4)\n",
    "\n",
    "model.to(device)\n",
    "train_loop(model,optimizer,train_dataloader,valid_dataloader,50,config['encode_mode'] ,device,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load best model and test on test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_from_checkpoint(model, optimizer, checkpoint_path, device):\n",
    "    \"\"\"\n",
    "    Loads the model and optimizer state from a checkpoint if it exists.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to load the state into.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n",
    "    - checkpoint_path (str): Path to the checkpoint file.\n",
    "    - device (torch.device): Device to which the model should be moved.\n",
    "    \n",
    "    Returns:\n",
    "    - start_epoch (int): The epoch to start training from.\n",
    "    - best_validation_loss (float): The best validation loss recorded in the checkpoint.\n",
    "    \"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}. Resuming from epoch {start_epoch}')\n",
    "        # print(f'Best validation loss: {best_validation_loss}')\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_validation_loss = float('inf')  # Assuming lower is better for validation loss\n",
    "        print('No checkpoint found.')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    return start_epoch, best_validation_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from ./weights/graph/(onehot)_(regloss)_(3GAT)/model_best.pt. Resuming from epoch 31\n",
      "Overall Reg Metrics - MSE: 0.4989, RMSE: 0.7063, MAE: 0.5328, R2: 0.7734, PCC: 0.8799\n",
      "Overall Classification Metrics - Accuracy: 0.8632, Precision: 0.6199, Recall: 0.7677, F1-Score: 0.6859, AUC-ROC: 0.9215, AUC-PR: 0.7733, MCC: 0.6053\n",
      "Processed model in path: ./weights/graph/(onehot)_(regloss)_(3GAT)/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of model paths\n",
    "model_paths = [\n",
    "    # \"./weights/graph/(onehot)_(regloss)_(3EGNN)/\",\n",
    "    \"./weights/graph/(onehot)_(regloss)_(3GAT)/\",\n",
    "    # \"./weights/graph/(onehot)_(regloss)_(3GCN)/\"\n",
    "  \n",
    "]\n",
    "\n",
    "for path in model_paths:\n",
    "    # Load the config for the current model\n",
    "    with open(path + 'config.json', 'r') as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "\n",
    "    # Initialize the model\n",
    "    if config['model']=='GCN':\n",
    "        model = GCNModel(num_feats = config[\"num_feats\"],\n",
    "                       graph_hidden_layer_output_dims = config[\"graph_hidden_layer_output_dims\"],\n",
    "                       linear_hidden_layer_output_dims = config[\"linear_hidden_layer_output_dims\"])\n",
    "    elif config['model']=='GAT':\n",
    "        model = GATModel(num_feats = config[\"num_feats\"],\n",
    "                        graph_hidden_layer_output_dims = config[\"graph_hidden_layer_output_dims\"],\n",
    "                        linear_hidden_layer_output_dims = config[\"linear_hidden_layer_output_dims\"])\n",
    "    else:\n",
    "        model = EGNN_Model(num_feats = config[\"num_feats\"],\n",
    "                        graph_hidden_layer_output_dims = config[\"graph_hidden_layer_output_dims\"],\n",
    "                        linear_hidden_layer_output_dims = config[\"linear_hidden_layer_output_dims\"])\n",
    "\n",
    "\n",
    "    # Load the model weights from the checkpoint\n",
    "    _, _ = load_model_from_checkpoint(model, optimizer, path + 'model_best.pt', device)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, metrics, preds, tar = evaluate(model, test_dataloader ,device)\n",
    "\n",
    "    # Save metrics of the best model\n",
    "    with open(path + 'result.json', 'w') as json_file:\n",
    "        json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "    print(f\"Processed model in path: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_load_graph_model(weight_path,device='cuda'):\n",
    "    config_path = os.path.join(weight_path, \"config.json\")\n",
    "\n",
    "    # Read the JSON file back into a dictionary\n",
    "    with open(config_path, 'r') as json_file:\n",
    "        config = json.load(json_file)\n",
    "    \n",
    "    model = EGNN_Model(num_feats = config[\"num_feats\"],\n",
    "                        graph_hidden_layer_output_dims = config[\"graph_hidden_layer_output_dims\"],\n",
    "                        linear_hidden_layer_output_dims = config[\"linear_hidden_layer_output_dims\"])\n",
    "\n",
    "\n",
    "    checkpoint_path = os.path.join(weight_path, \"model_best.pt\")\n",
    "\n",
    "    # checkpoint_path = os.path.abspath('../aggrepred/weights/both_loss_dif_layer/model_best.pt')\n",
    "\n",
    "    print(checkpoint_path)\n",
    "  \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print('Loading model succesfully')\n",
    "    else:\n",
    "        print('No model found')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/main/aggrepred/weights/graph/(onehot)_(regloss)_(3EGNN)/model_best.pt\n",
      "Loading model succesfully\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "EGNN_Model.forward() missing 1 required positional argument: 'edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print(graph_model)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache() \n\u001b[0;32m----> 8\u001b[0m loss, metrics, preds, tar \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 89\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, device, mode)\u001b[0m\n\u001b[1;32m     87\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     88\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 89\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     91\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m combined_loss(out, y\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# current_loss = weighted_bce_loss(out, (y>0).float().to(device)) + mse_loss(out, y.to(device))\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/aggrepred/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/aggrepred/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: EGNN_Model.forward() missing 1 required positional argument: 'edges'"
     ]
    }
   ],
   "source": [
    "graph_weight_path = \"/users/eleves-b/2023/ly-an.chhay/main/aggrepred/weights/graph/(onehot)_(regloss)_(3EGNN)\"\n",
    "##################################################################\n",
    "graph_model = define_load_graph_model(graph_weight_path)\n",
    "graph_model = graph_model.to(device)\n",
    "# print(graph_model)\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "loss, metrics, preds, tar = evaluate(graph_model, test_dataloader ,device)\n",
    "\n",
    "# # Save metrics of the best model\n",
    "# with open(path + 'result.json', 'w') as json_file:\n",
    "#     json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "# print(f\"Processed model in path: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= torch.load(\"/users/eleves-b/2023/ly-an.chhay/main/application/tmp/g.pt\")\n",
    "dataloader = graphDataLoader([g], batch_size=1, shuffle=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1239, 20], edge_index=[2, 25010], y=[1239], pos=[1239, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = 20\n",
    "graph_hidden_layer_output_dims = [20,20,20,20,20,20]\n",
    "linear_hidden_layer_output_dims = [10,10]\n",
    "\n",
    "\n",
    "best_pre_trained_model = EGNN_Model(num_feats = num_feats,\n",
    "                       graph_hidden_layer_output_dims = graph_hidden_layer_output_dims,\n",
    "                       linear_hidden_layer_output_dims = linear_hidden_layer_output_dims)\n",
    "\n",
    "weight_dir = \"/users/eleves-b/2023/ly-an.chhay/main/aggrepred/weights/\"\n",
    "\n",
    "checkpoint_path = weight_dir+'graph/6egnn_3FC_bothloss/model_best.pt'\n",
    "\n",
    "\n",
    "def load_model(model, checkpoint_path,device):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        model.to(device)\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}')\n",
    "    else:\n",
    "        print('No checkpoint found')\n",
    "    \n",
    "    return model\n",
    "\n",
    "best_pre_trained_model = load_model(best_pre_trained_model,checkpoint_path,device)\n",
    "\n",
    "# best_pre_trained_model.to(device)\n",
    "test_out, preds, trues = evaluate(best_pre_trained_model,test_dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = 20\n",
    "graph_hidden_layer_output_dims = [20,20,20]\n",
    "linear_hidden_layer_output_dims = [10,10]\n",
    "\n",
    "\n",
    "\n",
    "best_pre_trained_model = EGNN_Model(num_feats = num_feats,\n",
    "                       graph_hidden_layer_output_dims = graph_hidden_layer_output_dims,\n",
    "                       linear_hidden_layer_output_dims = linear_hidden_layer_output_dims)\n",
    "\n",
    "weight_dir = \"/users/eleves-b/2023/ly-an.chhay/main/aggrepred/weights/\"\n",
    "\n",
    "checkpoint_path = weight_dir+'graph/3egnn_3FC_bothloss/model_best.pt'\n",
    "\n",
    "\n",
    "def load_model(model, checkpoint_path,device):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        model.to(device)\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}')\n",
    "    else:\n",
    "        print('No checkpoint found')\n",
    "    \n",
    "    return model\n",
    "\n",
    "best_pre_trained_model = load_model(best_pre_trained_model,checkpoint_path,device)\n",
    "\n",
    "# best_pre_trained_model.to(device)\n",
    "test_out, metric, preds, trues = evaluate(best_pre_trained_model,test_dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aggrepred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
