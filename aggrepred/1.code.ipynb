{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import esm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "top_folder_path = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "sys.path.insert(0, top_folder_path)\n",
    "\n",
    "from aggrepred.dataset import *\n",
    "from aggrepred.model import *\n",
    "from aggrepred.utils import *\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, matthews_corrcoef\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset:\n",
    "    def __init__(self, df, max_seq_len=1000):\n",
    "        self.data = df.copy()\n",
    "        \n",
    "        self.data['scores'] = self.data['scores'].apply(ast.literal_eval)\n",
    "        \n",
    "        def count_pos_neg_values(lst):\n",
    "            count_pos = sum(1 for x in lst if x > 0)\n",
    "            count_neg = sum(1 for x in lst if x <= 0)\n",
    "            return count_pos, count_neg\n",
    "\n",
    "        # Apply the function to create new columns\n",
    "        self.data[['count_positive', 'count_negative']] = self.data['scores'].apply(count_pos_neg_values).apply(pd.Series)\n",
    "        self.data['len'] = self.data['scores'].apply(lambda x: len(x))\n",
    "        \n",
    "        self.data['neg_to_pos_ratio'] = self.data['count_negative'] / self.data['count_positive']\n",
    "        self.max_seq_len = max_seq_len\n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "   \n",
    "        if idx < 0 or idx >= len(self.data):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        row = self.data.iloc[idx]\n",
    "        code = row['ID']\n",
    "        seq = row['sequence']\n",
    "        scores = row['scores']\n",
    "        \n",
    "        y  = scores[:self.max_seq_len] + [0] * (self.max_seq_len - len(scores))\n",
    "        y = torch.tensor(y)\n",
    "\n",
    "        y_bin =  (y>0).int()\n",
    "\n",
    "        # Generate binary mask based on sequence length (1 for actual values, 0 for padding)\n",
    "        mask = torch.zeros(self.max_seq_len, dtype=torch.bool)\n",
    "        mask[:len(scores)] = True  # Set the first 'len(Hchain_scores)' to 1\n",
    "\n",
    "        return {\n",
    "            'code': code,\n",
    "            'seq': seq,\n",
    "            'target_reg': y,\n",
    "            'target_bin': y_bin,\n",
    "            'mask': mask\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# max length of the sequence set to 1000\n",
    "SEQ_MAX_LEN = 1000\n",
    "\n",
    "# 21 amino acids + 7 meiler features\n",
    "INPUT_FEATURES = 28\n",
    "\n",
    "# kernel size as per Parapred\n",
    "KERNEL_SIZE = 11\n",
    "\n",
    "# hidden output chanel of CNN\n",
    "HIDDEN_CHANNELS = 256\n",
    "\n",
    "\n",
    "\n",
    "def generate_mask(input_tensor: torch.Tensor, masks: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate a mask for masked 1D convolution based on a binary mask, including non-consecutive valid positions.\n",
    "\n",
    "    :param input_tensor: an input tensor for convolution (batch_size x features x max_seqlen)\n",
    "    :param masks: a binary mask (batch_size x max_seqlen) indicating valid positions\n",
    "    :return: mask (batch_size x features x max_seqlen)\n",
    "    \"\"\"\n",
    "    batch_size, channels, max_seqlen = input_tensor.shape\n",
    "\n",
    "    # Expand the binary mask to match the input tensor shape (batch_size x features x max_seqlen)\n",
    "    conv_mask = masks.unsqueeze(1).expand(batch_size, channels, max_seqlen)\n",
    "\n",
    "    return conv_mask.to(device=input_tensor.device)\n",
    "\n",
    "class LocalExtractorBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int = SEQ_MAX_LEN,\n",
    "                 output_dim: int = SEQ_MAX_LEN,\n",
    "                 in_channel: int = INPUT_FEATURES,\n",
    "                 out_channel: Optional[int] = None,\n",
    "                 kernel_size: int = KERNEL_SIZE,\n",
    "                 dilation: int = 1,\n",
    "                 stride: int = 1):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # Assert same shape\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = input_dim if output_dim is None else output_dim\n",
    "\n",
    "        self.in_channels = in_channel\n",
    "        self.out_channel = in_channel if out_channel is None else out_channel\n",
    "\n",
    "\n",
    "        # Determine the padding required for keeping the same sequence length\n",
    "        assert dilation >= 1 and stride >= 1, \"Dilation and stride must be >= 1.\"\n",
    "        self.dilation, self.stride = dilation, stride\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        padding = self.determine_padding(self.input_dim, self.output_dim)\n",
    "\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channel,\n",
    "            out_channel,\n",
    "            self.kernel_size,\n",
    "            padding=padding)\n",
    "\n",
    "        self.BN = nn.BatchNorm1d(out_channel)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor, binary_mask) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the LocalExtractorBlock\n",
    "\n",
    "        :param input_tensor: an input tensor of (bsz x features x seqlen) or (bsz x  x seqlen)\n",
    "        :param mask: a boolean tensor of (bsz x 1 x seqlen)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # self.conv.weight = self.conv.weight.to(input_tensor.device)\n",
    "        # self.conv.bias = self.conv.bias.to(input_tensor.device) if self.conv.bias is not None else None\n",
    "    \n",
    "        o = self.conv(input_tensor)\n",
    "        o = self.BN(o)\n",
    "        o = self.leakyrelu(o)\n",
    "        o = self.dropout(o)\n",
    "\n",
    "        #mask to zero-out values beyond the sequence length\n",
    "        mask = generate_mask(o, binary_mask)\n",
    "\n",
    "        return o * mask\n",
    "    \n",
    "    def determine_padding(self, input_shape: int, output_shape: int) -> int:\n",
    "        \"\"\"\n",
    "        Determine the padding required to keep the same length of the sequence before and after convolution.\n",
    "\n",
    "        formula :  L_out = ((L_in + 2 x padding - dilation x (kernel_size - 1) - 1)/stride + 1)\n",
    "\n",
    "        :return: An integer defining the amount of padding required to keep the \"same\" padding effect\n",
    "        \"\"\"\n",
    "        padding = (((output_shape - 1) * self.stride) + 1 - input_shape + (self.dilation * (self.kernel_size - 1))) // 2\n",
    "\n",
    "        # Ensure padding is non-negative and output shape is consistent\n",
    "        assert padding >= 0, f\"Padding must be non-negative but got {padding}.\"\n",
    "        return padding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_attn_mask(batch_size, num_heads, max_length, masks):\n",
    "    \"\"\"\n",
    "    Generate an attention mask from a provided binary mask.\n",
    "\n",
    "    :param batch_size: int, size of the batch.\n",
    "    :param num_heads: int, number of attention heads.\n",
    "    :param max_length: int, maximum sequence length.\n",
    "    :param masks: a binary mask (batch_size x max_length) indicating the valid positions.\n",
    "    :return: expanded mask for multi-head attention (batch_size * num_heads x max_length x max_length)\n",
    "    \"\"\"\n",
    "    # Initialize a 3D attention mask (batch_size x max_length x max_length)\n",
    "    attn_mask = torch.zeros((batch_size, max_length, max_length), dtype=torch.bool)\n",
    "    \n",
    "\n",
    "    # Populate the attention mask based on the input binary masks\n",
    "    for i, mask in enumerate(masks):\n",
    "        # Use the binary mask to determine valid positions\n",
    "        attn_mask[i] = torch.outer(mask, mask)\n",
    "        attn_mask[i].fill_diagonal_(True)\n",
    "    \n",
    "    # Expand the mask for multiple attention heads\n",
    "    attn_mask = attn_mask.unsqueeze(1).expand(-1, num_heads, -1, -1)\n",
    "    \n",
    "    # Reshape to merge batch and head dimensions\n",
    "    attn_mask = attn_mask.reshape(batch_size * num_heads, max_length, max_length)\n",
    "\n",
    "    return attn_mask\n",
    "\n",
    "class Att_BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=True, rnn_dropout=0.2, num_heads=1):\n",
    "        super(Att_BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                            bidirectional=bidirectional, batch_first=True, dropout=rnn_dropout if num_layers > 1 else 0)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size * 2 if bidirectional else hidden_size, num_heads=num_heads, batch_first=True)\n",
    "    \n",
    "    def forward(self, x, banary_mask):\n",
    "        \"\"\"\n",
    "        Forward pass through BiLSTM with Multi-Head Attention\n",
    "        \"\"\"\n",
    "        # Packed sequences are not necessary since we are using a mask.\n",
    "        h0 = torch.randn(2 * self.num_layers if self.bidirectional else self.num_layers,\n",
    "                        x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.randn(2 * self.num_layers if self.bidirectional else self.num_layers,\n",
    "                        x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward pass through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Apply MultiHeadAttention\n",
    "        mask = generate_attn_mask(x.size(0),self.num_heads, x.size(1), banary_mask).to(device=output.device)\n",
    "        attn_output, attn_weight = self.attention(output, output, output, attn_mask=~mask)\n",
    "\n",
    "        # mask = generate_attn_mask(x.size(0),self.num_heads, x.size(1), lengths).to(x.device)    #(batch_size, max_length, max_length)\n",
    "        # # attn_output, attn_weight = self.attention(output, output, output)\n",
    "        # attn_output, attn_weight = self.attention(output, output, output, attn_mask=~mask)\n",
    "\n",
    "        return attn_output, (hn, cn)\n",
    "    \n",
    "  \n",
    "    \n",
    "class GlobalInformationExtractor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=True, rnn_dropout=0.2, num_heads=1):\n",
    "        super(GlobalInformationExtractor, self).__init__()\n",
    "        self.att_bilstm = Att_BiLSTM(input_size, hidden_size, num_layers, bidirectional, rnn_dropout, num_heads)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        output, (hn,cn) = self.att_bilstm(x, lengths)\n",
    "        output = self.leakyrelu(output)\n",
    "        output = self.dropout(output)\n",
    "        return output, (hn, cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggrepred(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the Aggrepred model using a configuration dictionary.\n",
    "\n",
    "        :param config: A dictionary containing all the parameters for the model.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Unpack the configuration dictionary\n",
    "        # self.pooling = config.get([\"pooling\"], False)\n",
    "        # self.use_local = config[\"use_local\"]\n",
    "        # # self.use_local = config.get(\"use_local\", False)\n",
    "        # self.use_global = config.get(\"use_global\", False)\n",
    "\n",
    "        self.pooling = config.get(\"pooling\", False) \n",
    "        self.use_local = config.get(\"use_local\", True)  # Default to False if not in config\n",
    "        self.use_global = config.get(\"use_global\", True)\n",
    "        \n",
    "        num_localextractor_block = config.get(\"num_localextractor_block\", 3)\n",
    "        input_dim = config.get(\"input_dim\", 1000)\n",
    "        output_dim = config.get(\"output_dim\", 1000)\n",
    "        in_channel = config.get(\"in_channel\", 28)\n",
    "        out_channel = config.get(\"out_channel\", None)\n",
    "        kernel_size = config.get(\"kernel_size\", 23)\n",
    "        dilation = config.get(\"dilation\", 1)\n",
    "        stride = config.get(\"stride\", 1)\n",
    "        \n",
    "        rnn_hid_dim = config.get(\"rnn_hid_dim\", 256)\n",
    "        rnn_layers = config.get(\"rnn_layers\", 1)\n",
    "        bidirectional = config.get(\"bidirectional\", True)\n",
    "        rnn_dropout = config.get(\"rnn_dropout\", 0.2)\n",
    "        attention_heads = config.get(\"attention_heads\", 1)\n",
    "\n",
    "        # assert self.use_local or self.use_global, \"At least one of the local or global information extractor must be used.\"\n",
    "\n",
    "        out_channel = in_channel if out_channel is None else out_channel\n",
    "        \n",
    "        if self.use_local:\n",
    "            assert num_localextractor_block > 0, \"Number of local extractor blocks must be greater than 0.\"\n",
    "            self.local_extractors = nn.ModuleList([\n",
    "                LocalExtractorBlock(\n",
    "                    input_dim=input_dim,\n",
    "                    output_dim=output_dim,\n",
    "                    in_channel=in_channel if i == 0 else out_channel,\n",
    "                    out_channel=out_channel,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation = dilation,\n",
    "                    stride = stride\n",
    "                ) for i in range(num_localextractor_block)\n",
    "            ])\n",
    "            self.residue_map = nn.Linear(in_channel,out_channel)\n",
    "        \n",
    "        if self.use_global:\n",
    "            self.global_extractor = GlobalInformationExtractor(input_size=in_channel, hidden_size=rnn_hid_dim, num_layers=rnn_layers, bidirectional=bidirectional, rnn_dropout=rnn_dropout, num_heads=attention_heads)\n",
    "\n",
    "        \n",
    "        rnn_hid_dim = rnn_hid_dim * 2 if bidirectional else rnn_hid_dim\n",
    "\n",
    "        # if self.use_local:\n",
    "        #     fc_in_dim = out_channel + rnn_hid_dim  if self.use_global else out_channel\n",
    "        # else:\n",
    "        #     fc_in_dim = rnn_hid_dim \n",
    "\n",
    "        if self.use_local and self.use_global:\n",
    "            fc_in_dim = out_channel + rnn_hid_dim\n",
    "        elif self.use_local:\n",
    "            fc_in_dim = out_channel\n",
    "        elif self.use_global:\n",
    "            fc_in_dim = rnn_hid_dim\n",
    "        else:\n",
    "            fc_in_dim = in_channel\n",
    "\n",
    "        # if self.pooling:\n",
    "        #     self.downproject = nn.Linear(fc_in_dim, 4)\n",
    "        #     fc_in_dim = 4* input_dim\n",
    "        \n",
    "        self.reg_layer = nn.Sequential(\n",
    "            nn.Linear(fc_in_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    " \n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor, binary_mask) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        #### Local Extracted Information\n",
    "        # residual connection following 3 layers of local extractor blocks \n",
    "\n",
    "        if self.use_local:\n",
    "            residue = self.residue_map(input_tensor)\n",
    "            o = input_tensor.permute(0, 2, 1)\n",
    "            residue = residue.permute(0, 2, 1)\n",
    "            for extractor in self.local_extractors:\n",
    "                o = extractor(o, binary_mask)\n",
    "                o = o + residue\n",
    "                residue = o\n",
    "\n",
    "            # print('in',input_tensor.size())\n",
    "            # print('out:',o.size())\n",
    "        \n",
    "\n",
    "            local_extracted_info = o.permute(0, 2, 1)\n",
    "\n",
    "            # print('local:',local_extracted_info.size())\n",
    "\n",
    "\n",
    "        #### Local Extracted Information\n",
    "        if self.use_global:\n",
    "            global_extracted_info, (hn,cn) = self.global_extractor(input_tensor, binary_mask)\n",
    "\n",
    "        \n",
    "        # print('global:',global_extracted_info.size())\n",
    "\n",
    "        # # Concatenate the local and global information\n",
    "        # if self.use_local:\n",
    "        #     final_info = torch.cat((local_extracted_info,global_extracted_info), dim=-1) if self.use_global else local_extracted_info\n",
    "        # else:\n",
    "        #     final_info = global_extracted_info\n",
    "\n",
    "        if self.use_local and self.use_global:\n",
    "            final_info = torch.cat((local_extracted_info, global_extracted_info), dim=-1)\n",
    "        elif self.use_local:\n",
    "            final_info = local_extracted_info\n",
    "        elif self.use_global:\n",
    "            final_info = global_extracted_info\n",
    "        else:\n",
    "            final_info = input_tensor\n",
    "\n",
    "        reg_output = self.reg_layer(final_info)\n",
    "        \n",
    "        return final_info, reg_output\n",
    "  \n",
    "\n",
    "def clean_output(output_tensor: torch.Tensor, binary_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Clean the output tensor of probabilities to remove the predictions for padded positions using a binary mask.\n",
    "\n",
    "    :param output_tensor: output from the Parapred model; shape: (max_length x 1)\n",
    "    :param binary_mask: binary mask for the sequence; shape: (max_length, ), where True indicates valid positions.\n",
    "\n",
    "    :return: cleaned output tensor; shape: (sum(binary_mask), )\n",
    "    \"\"\"\n",
    "    # Use the binary mask to filter out the padded positions\n",
    "    return output_tensor[binary_mask].view(-1)\n",
    "\n",
    "def clean_output_batch(output_tensor: torch.Tensor, binary_masks: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Clean the output tensor of probabilities to remove the predictions for padded positions in a batch using binary masks.\n",
    "\n",
    "    :param output_tensor: output from the Parapred model; shape: (batch_size, max_length, 1)\n",
    "    :param binary_masks: binary masks for the sequences; shape: (batch_size, max_length), where True indicates valid positions.\n",
    "\n",
    "    :return: cleaned output tensor; shape: (sum of valid positions across the batch, )\n",
    "    \"\"\"\n",
    "    batch_size, max_length, _ = output_tensor.shape\n",
    "    cleaned_outputs = []\n",
    "\n",
    "    # Loop over each sequence in the batch\n",
    "    for i in range(batch_size):\n",
    "        # Use the binary mask to filter out the padded positions for each sequence\n",
    "        cleaned_outputs.append(output_tensor[i][binary_masks[i]].view(-1))\n",
    "\n",
    "    # Concatenate the cleaned outputs from all sequences\n",
    "    return torch.cat(cleaned_outputs, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# ----------------\n",
    "# PARAM\n",
    "# ----------------\n",
    "\n",
    "\n",
    "\n",
    "# Define the configuration dictionary with all the model parameters\n",
    "# path = \"./weights/seq/(esm35M)_(regloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path = \"./weights/seq/(esm35M)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "path = \"./weights/seq/(esm35M)_(combinedloss)_()/\"\n",
    "# path = \"./weights/seq/(esm)_(regloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path = \"./weights/seq/(protbert)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path = \"./weights/seq/(protbert)_(combinedloss)_(none)/\"\n",
    "# path = \"./weights/seq/()_(combinedloss)_(none)/\"\n",
    "# path = \"./weights/seq/(onehot_meiler)_(regloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "# path = \"./weights/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\"\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"antibody\": False,\n",
    "    \"use_local\": False,\n",
    "    # \"use_local\": True,\n",
    "    \"use_global\": False,\n",
    "    # \"use_global\": True,\n",
    "    \"num_localextractor_block\": 3,\n",
    "    \"input_dim\": 1000,\n",
    "    \"output_dim\": 1000,\n",
    "    \"in_channel\": 480,\n",
    "    \"out_channel\": 256,\n",
    "    \"kernel_size\": 23,\n",
    "    \"dilation\": 1,\n",
    "    \"stride\": 1,\n",
    "    \"rnn_hid_dim\": 128,\n",
    "    \"rnn_layers\": 1,\n",
    "    \"bidirectional\": True,\n",
    "    \"rnn_dropout\": 0.2,\n",
    "    \"attention_heads\": 4,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 32,\n",
    "    \"nb_epochs\": 20,\n",
    "    \"encode_mode\" : 'esm'\n",
    "}\n",
    "\n",
    "# with open(path+'config.json', 'r') as json_file:\n",
    "#     config = json.load(json_file)\n",
    "\n",
    "\n",
    "# ----------------\n",
    "#  MODEL \n",
    "# ----------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = Aggrepred(config)\n",
    "model = model.to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 156161\n",
      "Number of non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------\n",
    "#   OPTIMIZER \n",
    "# ----------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "# optimizer = nn.optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "#                                 betas=(0.9, 0.999),\n",
    "#                                 weight_decay=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# LOSS\n",
    "# ----------------\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, lambda_reg=1.0, lambda_bin=1.0, pos_weight=None):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.lambda_bin = lambda_bin\n",
    "        self.mse_loss = nn.MSELoss()  # Regression Loss (MSE)\n",
    "        \n",
    "        if pos_weight is not None:\n",
    "            # Binary Classification Loss (Weighted BCE with logits)\n",
    "            self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "        else:\n",
    "            self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, outputs, regression_targets):\n",
    "        # Calculate regression loss\n",
    "        reg_loss = self.mse_loss(outputs, regression_targets)\n",
    "        \n",
    "        # Calculate binary classification loss\n",
    "        # Convert regression output to binary labels (logits) for classification\n",
    "        binary_targets = (regression_targets> 0).float()\n",
    "        bin_loss = self.bce_loss(outputs, binary_targets)\n",
    "        \n",
    "        # Combined weighted loss\n",
    "        total_loss = self.lambda_reg * reg_loss + self.lambda_bin * bin_loss\n",
    "        return total_loss\n",
    "\n",
    "mse_loss  = nn.MSELoss()\n",
    "pos_class_weights = torch.Tensor([4.0]).to(device)\n",
    "weighted_bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_class_weights)\n",
    "\n",
    "\n",
    "combined_loss = CombinedLoss(lambda_reg=0.7, lambda_bin=0.3, pos_weight=4.0)\n",
    "\n",
    "\n",
    "# ----------------\n",
    "def count_parameters(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    return trainable_params, non_trainable_params\n",
    "\n",
    "trainable, non_trainable = count_parameters(model)\n",
    "print(f\"Number of trainable parameters: {trainable}\")\n",
    "print(f\"Number of non-trainable parameters: {non_trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# DATA\n",
    "# ----------------\n",
    "\n",
    "def custom_collate(batch):\n",
    "    regs_tensor = [item['target_reg'] for item in batch]\n",
    "    mask = [item['mask'] for item in batch]\n",
    "    max_len = regs_tensor[0].size()[0]  #1000\n",
    "    \n",
    "    orig_lens = [item['mask'].sum() for item in batch]\n",
    "    max_orig_len = min(max(orig_lens), max_len)  # Ensure max_orig_len is at most max_len\n",
    "    \n",
    "    # print(max_orig_len)\n",
    "    # truncated_encoded_seqs = [item['encoded_seq'][:max_orig_len,:] for item in batch]\n",
    "    codes = [item['code'] for item in batch]\n",
    "    seqs = [item['seq'] for item in batch]\n",
    "    truncated_regs_tensor = [item['target_reg'][ :max_orig_len] for item in batch]\n",
    "    truncated_bins_tensor = [item['target_bin'][:max_orig_len] for item in batch]\n",
    "    truncated_mask_tensor = [item['mask'][ :max_orig_len] for item in batch]\n",
    "    \n",
    "    # encoded_seqs_tensor = torch.stack(truncated_encoded_seqs)\n",
    "    target_regs_tensor = torch.stack(truncated_regs_tensor)\n",
    "    target_bins_tensor = torch.stack(truncated_bins_tensor)\n",
    "    mask_tensor = torch.stack(truncated_mask_tensor)\n",
    "\n",
    "    return {\n",
    "        'code': codes,\n",
    "        'seq': seqs,\n",
    "        'target_reg': target_regs_tensor,\n",
    "        'target_bin': target_bins_tensor,\n",
    "        'mask': mask_tensor\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "df = pd.read_csv(\"../data/csv/data60_fixed_split.csv\")\n",
    "\n",
    "\n",
    "# ## smaple down abit for esm\n",
    "if config['encode_mode'] not in ['onehot', 'onehot_meiler']:\n",
    "    print(\"yes\")\n",
    "    train_dataset = SeqDataset(df[df.split=='train'].sample(frac=0.10, random_state=42),1000)\n",
    "    valid_dataset = SeqDataset(df[df.split=='valid'].sample(frac=0.10, random_state=42),1000)\n",
    "    test_dataset = SeqDataset(df[df.split=='test'],1000)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate)\n",
    "else:\n",
    "    train_dataset = SeqDataset(df[df.split=='train'],1000)\n",
    "    valid_dataset = SeqDataset(df[df.split=='valid'],1000)\n",
    "    test_dataset = SeqDataset(df[df.split=='test'],1000)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##collate to flexible max len in batch\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "# valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esm_model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "# # esm_model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
    "# # esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "# esm_model = esm_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# protbert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "# protbert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to('cuda')\n",
    "\n",
    "\n",
    "# for idx, batch in enumerate(test_dataloader):\n",
    "#     print(batch['mask'].size())\n",
    "#     print(batch['mask'])\n",
    "#     x = embed_protbert_batch(batch['seq'],protbert_model,protbert_tokenizer)\n",
    "#     print(x.size())\n",
    "#     x = embed_esm_batch(batch['seq'],esm_model, alphabet)\n",
    "#     print(x.size())\n",
    "#     if idx == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = embed_esm_batch(['D'],esm_model, alphabet)\n",
    "# print(x.size())\n",
    "# x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the propostion of pos/neg class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### there are about 80% of negative class vs 20% of positive class  , hence 4:1 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "propotion of position and negative class:  0.1874447907578202 0.8125552092421798\n",
      "ratio of position to negative class:  4.334904192093585\n",
      "propotion of position and negative class:  0.19428551851724965 0.8057144814827504\n",
      "ratio of position to negative class:  4.147064009874802\n",
      "propotion of position and negative class:  0.1936254280065119 0.8063745719934882\n",
      "ratio of position to negative class:  4.164610920660527\n"
     ]
    }
   ],
   "source": [
    "sum_one = train_dataset.data['count_positive'].sum()\n",
    "sum_zero = train_dataset.data['count_negative'].sum()\n",
    "total = train_dataset.data['len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)\n",
    "\n",
    "sum_one = valid_dataset.data['count_positive'].sum()\n",
    "sum_zero = valid_dataset.data['count_negative'].sum()\n",
    "total = valid_dataset.data['len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)\n",
    "\n",
    "sum_one = test_dataset.data['count_positive'].sum()\n",
    "sum_zero = test_dataset.data['count_negative'].sum()\n",
    "total = test_dataset.data['len'].sum() \n",
    "\n",
    "print(\"propotion of position and negative class: \" , sum_one/total, sum_zero/total)\n",
    "print(\"ratio of position to negative class: \" , sum_zero/sum_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrepred(\n",
      "  (reg_layer): Sequential(\n",
      "    (0): Linear(in_features=480, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.1)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_time(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes}m {seconds} s\" if minutes>0 else f\"{seconds} s\"\n",
    "\n",
    "def train_epoch(model, optimizer, dataloader,loss_function, encode_mode='onehot_meiler', device = 'cuda', printEvery=100):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    count_iter = 0\n",
    "    start_time = time.time()\n",
    "    epoch_start_time = start_time\n",
    "    batch_size = dataloader.batch_size\n",
    "    printEvery = printEvery // batch_size if batch_size else 100  # Adjust printEvery based on batch size\n",
    "\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    esm_model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    esm_model = esm_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    protbert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "    protbert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to('cuda')\n",
    "\n",
    "    with tqdm(total=len(dataloader), desc='Training', unit='batch') as pbar:\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "                 \n",
    "            batch_sequences = batch['seq']\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            \n",
    "            ## different encoding here\n",
    "            if encode_mode == 'esm':\n",
    "                x = embed_esm_batch(batch_sequences, esm_model, alphabet).to(device)\n",
    "            elif encode_mode == 'protbert':\n",
    "                x = embed_protbert_batch(batch_sequences, protbert_model, protbert_tokenizer).to(device)\n",
    "            elif encode_mode == 'onehot':\n",
    "                x = onehot_encode_batch(batch_sequences,1000).to(device)\n",
    "            else:\n",
    "                x = onehot_meiler_encode_batch(batch_sequences,1000).to(device)\n",
    "\n",
    "\n",
    "            ## convert (bsz,max_len) to  (bsz,max_len,1)\n",
    "            y_reg = batch['target_reg'].unsqueeze(2).float().to(device)\n",
    "            y_bin = batch['target_bin'].unsqueeze(2).float().to(device)\n",
    "\n",
    "            \n",
    "            # print(\"mask:\",mask.size())\n",
    "            # print(\"y:\",y_reg.size())\n",
    "            # print('x', x.size())\n",
    "            \n",
    "            y_reg = clean_output_batch(y_reg, mask)\n",
    "            y_bin = clean_output_batch(y_bin, mask)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            ### predict \n",
    "            final_info, output_reg = model(x, mask)\n",
    "            \n",
    "            #trim out the padded part\n",
    "            output_reg = clean_output_batch(output_reg, mask)\n",
    "            # print(orig_len.sum())\n",
    "            assert len(output_reg)==len(y_reg) , 'reg output {} and target {} not same length'.format(len(output_reg),len(y_reg))\n",
    "\n",
    "            # current_loss = reg_loss \n",
    "            current_loss = loss_function(output_reg, y_reg)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            current_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += current_loss.item()\n",
    "            \n",
    "            printEvery = int(1000/x.size(0))\n",
    "            count_iter += 1\n",
    "            if count_iter % printEvery == 0 or idx == len(dataloader) - 1:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                remaining_time = (elapsed_time / count_iter) * (len(dataloader) - count_iter)\n",
    "                print(f\"Iteration: {count_iter}, Time: {format_time(elapsed_time)}, Remaining: {format_time(remaining_time)}, Training Loss: {total_loss / count_iter:.4f}\")\n",
    "                start_time = time.time()\n",
    "            torch.cuda.empty_cache()\n",
    "            pbar.update(1)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"==> Average Training loss: mse ={total_loss / len(dataloader)}\")\n",
    "    print(f\"==> Epoch Training Time: {format_time(epoch_time)}\")\n",
    "    print(f\"================================================================\\n\")\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader,loss_function, encode_mode='onehot_meiler', device= 'cuda', mode='valid'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    predictions = []\n",
    "    targets = []\n",
    "    binary_predictions = []\n",
    "    binary_targets = []\n",
    "    orig_lens = []\n",
    "\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    esm_model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t30_150M_UR50D()\n",
    "    # esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    esm_model = esm_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    protbert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "    protbert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\").to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "\n",
    "            batch_sequences = batch['seq']\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            ## different encoding here\n",
    "            if encode_mode == 'esm':\n",
    "                x = embed_esm_batch(batch_sequences, esm_model, alphabet).to(device)\n",
    "            elif encode_mode == 'protbert':\n",
    "                x = embed_protbert_batch(batch_sequences, protbert_model, protbert_tokenizer).to(device)\n",
    "            elif encode_mode == 'onehot':\n",
    "                x = onehot_encode_batch(batch_sequences).to(device)\n",
    "            else:\n",
    "                x = onehot_meiler_encode_batch(batch_sequences).to(device)\n",
    "\n",
    "            ## convert (bsz,max_len) to  (bsz,max_len,1)\n",
    "            y_reg = batch['target_reg'].unsqueeze(2).float().to(device)\n",
    "            y_bin = batch['target_bin'].unsqueeze(2).float().to(device)\n",
    "            \n",
    "            y_reg = clean_output_batch(y_reg, mask)\n",
    "            y_bin = clean_output_batch(y_bin, mask)\n",
    "\n",
    "            ### predict \n",
    "            final_info, output_reg = model(x, mask)\n",
    "            \n",
    "            #trim out the padded part\n",
    "            output_reg = clean_output_batch(output_reg, mask)\n",
    "            # print(orig_len.sum())\n",
    "            assert len(output_reg)==len(y_reg) , 'reg output {} and target {} not same length'.format(len(output_reg),len(y_reg))\n",
    "\n",
    "            # current_loss = reg_loss \n",
    "            current_loss = loss_function(output_reg, y_reg)\n",
    "     \n",
    "            total_loss += current_loss.item()\n",
    "\n",
    "            #append to list of all preds\n",
    "            predictions.append(output_reg.cpu().numpy())\n",
    "            targets.append(y_reg.cpu().numpy())\n",
    "\n",
    "            ################################################################################\n",
    "            # y_bin = (y_reg.cpu().numpy() > 0.5).astype(int)\n",
    "            # out_bin = (output_reg.cpu().numpy() > 0.5).astype(int)\n",
    "            y_bin = (y_reg.cpu().numpy() > 0).astype(int)\n",
    "            out_bin = (output_reg.cpu().numpy() > 0).astype(int)\n",
    "            ################################################################################\n",
    "\n",
    "            binary_predictions.append(out_bin)\n",
    "            binary_targets.append(y_bin)\n",
    "\n",
    "    # if mode == 'test':\n",
    "    all_predictions = np.concatenate(predictions, axis=0).reshape(-1)\n",
    "    all_targets = np.concatenate(targets, axis=0).reshape(-1)\n",
    "    all_binary_predictions = np.concatenate(binary_predictions, axis=0).reshape(-1)\n",
    "    all_binary_targets = np.concatenate(binary_targets, axis=0).reshape(-1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_mse = mean_squared_error(all_targets, all_predictions)\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "    overall_mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    overall_r2 = r2_score(all_targets, all_predictions)\n",
    "    overall_pcc, _ = pearsonr(all_targets.flatten(), all_predictions.flatten())\n",
    "\n",
    "    # Calculate binary classification metrics\n",
    "    overall_accuracy = accuracy_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_precision = precision_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_recall = recall_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_f1 = f1_score(all_binary_targets, all_binary_predictions)\n",
    "    overall_auc_roc = roc_auc_score(all_binary_targets, all_predictions)\n",
    "    overall_auc_pr = average_precision_score(all_binary_targets, all_predictions)\n",
    "    overall_mcc = matthews_corrcoef(all_binary_targets, all_binary_predictions)\n",
    "\n",
    "    print(f\"Overall Regression Metrics\")\n",
    "    print(f\"MSE: {overall_mse:.4f}, RMSE: {overall_rmse:.4f}, MAE: {overall_mae:.4f}, R2: {overall_r2:.4f}, PCC: {overall_pcc:.4f}\")\n",
    "\n",
    "    print(f\"Overall classification Metrics\")\n",
    "    print(f\"Acc: {overall_accuracy:.4f}, Precision: {overall_precision:.4f}, Recall: {overall_recall:.4f}, F1-Score: {overall_f1:.4f}, AUC-ROC: {overall_auc_roc:.4f}, AUC-PR: {overall_auc_pr:.4f}, MCC: {overall_mcc:.4f}\")  \n",
    "    \n",
    "    metrics = {\n",
    "        \"Regression Metrics\": {\n",
    "            \"MSE\": round(float(overall_mse), 4),\n",
    "            \"RMSE\": round(float(overall_rmse), 4),\n",
    "            \"MAE\": round(float(overall_mae), 4),\n",
    "            \"R2\": round(float(overall_r2), 4),\n",
    "            \"PCC\": round(float(overall_pcc), 4)\n",
    "        },\n",
    "        \"Classification Metrics\": {\n",
    "            \"Accuracy\": round(float(overall_accuracy), 4),\n",
    "            \"Precision\": round(float(overall_precision), 4),\n",
    "            \"Recall\": round(float(overall_recall), 4),\n",
    "            \"F1-Score\": round(float(overall_f1), 4),\n",
    "            \"AUC-ROC\": round(float(overall_auc_roc), 4),\n",
    "            \"AUC-PR\": round(float(overall_auc_pr), 4),\n",
    "            \"MCC\": round(float(overall_mcc), 4)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    return total_loss / len(dataloader),metrics, predictions, targets\n",
    "\n",
    "def train_loop(model, optimizer, train_dataloader, valid_dataloader,loss_function, nb_epochs, encode_mode='onehot_meiler', device= 'cuda', save_directory='./weights/'):\n",
    "    start_epoch = 1\n",
    "    best_validation_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    # Paths for saving losses and metrics\n",
    "    loss_output_path = os.path.join(save_directory, 'losses.json')\n",
    "    metric_output_path = os.path.join(save_directory, 'metrics.json')\n",
    "    \n",
    "    # Initialize lists for losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "        print(f'Created directory: {save_directory}')\n",
    "\n",
    "    checkpoint_path = os.path.join(save_directory, 'model_last.pt')\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}. Resuming from epoch {start_epoch}')\n",
    "        \n",
    "        # Load losses from the losses.json file if it exists\n",
    "        if os.path.exists(loss_output_path):\n",
    "            with open(loss_output_path, 'r') as f:\n",
    "                losses = json.load(f)\n",
    "                train_losses = losses.get('train_losses', [])\n",
    "                val_losses = losses.get('val_losses', [])\n",
    "            print(f'Loaded losses from {loss_output_path}.')\n",
    "            print(train_losses)\n",
    "            print(val_losses)\n",
    "        else:\n",
    "            print(f'No losses file found at {loss_output_path}.')\n",
    "\n",
    "    else:\n",
    "        print('No checkpoint found. Starting from beginning.')\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    # # Load existing losses if available\n",
    "    # if os.path.exists(loss_output_path):\n",
    "    #     with open(loss_output_path, 'r') as json_file:\n",
    "    #         existing_losses = json.load(json_file)\n",
    "    #         train_losses = existing_losses.get('train_losses', [])\n",
    "    #         val_losses = existing_losses.get('val_losses', [])\n",
    "\n",
    "    for epoch in range(start_epoch, nb_epochs + 1):\n",
    "        print(\"==================================================================================\")\n",
    "        print(f'                            -----EPOCH {epoch}-----')\n",
    "        print(\"==================================================================================\")\n",
    "        \n",
    "        train_loss = train_epoch(model, optimizer, train_dataloader,loss_function, encode_mode ,device, printEvery=1000)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # # **Print Gradients**\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f'Gradient - {name}: {param.grad.norm()}')  # Prints the norm of gradients\n",
    "\n",
    "        print(\"==========================VALIDATION===============================================\")\n",
    "        val_loss ,metrics, _ , _ = evaluate(model, valid_dataloader,loss_function,encode_mode, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'==> Epoch {epoch} - Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < best_validation_loss:\n",
    "            early_stopping_counter = 0\n",
    "            best_validation_loss = val_loss\n",
    "            best_model_save_path = os.path.join(save_directory, 'model_best.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'validation_accuracy': val_loss,\n",
    "            }, best_model_save_path)\n",
    "            print('\\n')\n",
    "            print(f'Best model checkpoint saved to: {best_model_save_path}')\n",
    "\n",
    "            # Save metrics of the best model\n",
    "            with open(metric_output_path, 'w') as json_file:\n",
    "                json.dump(metrics, json_file, indent=4)\n",
    "        \n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= 5:\n",
    "                print(\"\\n==> Early stopping triggered. No improvement in validation loss for 3 epochs.\")\n",
    "                break\n",
    "\n",
    "        last_model_save_path = os.path.join(save_directory, 'model_last.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'validation_accuracy': val_loss,\n",
    "        }, last_model_save_path)\n",
    "        print(f'Last epoch model saved to: {last_model_save_path}')\n",
    "\n",
    "        # Save updated losses to the JSON file\n",
    "        losses = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }\n",
    "        with open(loss_output_path, 'w') as json_file:\n",
    "            json.dump(losses, json_file, indent=4)\n",
    "        print(f'Losses updated and saved to: {loss_output_path}')\n",
    "        \n",
    "        print(\"==================================================================================\\n\")\n",
    "    \n",
    "        \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path, exist_ok=True)\n",
    "with open(os.path.join(path, \"config.json\"), 'w') as json_file:\n",
    "    json.dump(config, json_file, indent=4)\n",
    "\n",
    "\n",
    "loss_function = combined_loss\n",
    "# loss_function = mse_loss\n",
    "\n",
    "train_loop(model,optimizer,train_dataloader,valid_dataloader,loss_function, 50, config['encode_mode'],device,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_model_from_checkpoint(model, optimizer, checkpoint_path, device):\n",
    "    \"\"\"\n",
    "    Loads the model and optimizer state from a checkpoint if it exists.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to load the state into.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer to load the state into.\n",
    "    - checkpoint_path (str): Path to the checkpoint file.\n",
    "    - device (torch.device): Device to which the model should be moved.\n",
    "    \n",
    "    Returns:\n",
    "    - start_epoch (int): The epoch to start training from.\n",
    "    - best_validation_loss (float): The best validation loss recorded in the checkpoint.\n",
    "    \"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_validation_loss = checkpoint['validation_accuracy']\n",
    "        print(f'Loaded checkpoint from {checkpoint_path}. Resuming from epoch {start_epoch}')\n",
    "        # print(f'Best validation loss: {best_validation_loss}')\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_validation_loss = float('inf')  # Assuming lower is better for validation loss\n",
    "        print('No checkpoint found.')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    return start_epoch, best_validation_loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from ./weights/seq/(onehot)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/model_best.pt. Resuming from epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2023/ly-an.chhay/.conda/envs/aggrepred/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1000) must match the existing size (908) at non-singleton dimension 2.  Target sizes: [32, 256, 1000].  Tensor sizes: [32, 1, 908]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m load_model_from_checkpoint(model, optimizer, path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, device)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m loss, metrics, preds, tar \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcombined_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencode_mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Save metrics of the best model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n",
      "Cell \u001b[0;32mIn[26], line 138\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, loss_function, encode_mode, device, mode)\u001b[0m\n\u001b[1;32m    135\u001b[0m y_bin \u001b[38;5;241m=\u001b[39m clean_output_batch(y_bin, mask)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m### predict \u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m final_info, output_reg \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#trim out the padded part\u001b[39;00m\n\u001b[1;32m    141\u001b[0m output_reg \u001b[38;5;241m=\u001b[39m clean_output_batch(output_reg, mask)\n",
      "File \u001b[0;32m~/.conda/envs/aggrepred/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/aggrepred/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 108\u001b[0m, in \u001b[0;36mAggrepred.forward\u001b[0;34m(self, input_tensor, binary_mask)\u001b[0m\n\u001b[1;32m    106\u001b[0m residue \u001b[38;5;241m=\u001b[39m residue\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m extractor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_extractors:\n\u001b[0;32m--> 108\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     o \u001b[38;5;241m=\u001b[39m o \u001b[38;5;241m+\u001b[39m residue\n\u001b[1;32m    110\u001b[0m     residue \u001b[38;5;241m=\u001b[39m o\n",
      "File \u001b[0;32m~/.conda/envs/aggrepred/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/aggrepred/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 85\u001b[0m, in \u001b[0;36mLocalExtractorBlock.forward\u001b[0;34m(self, input_tensor, binary_mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(o)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#mask to zero-out values beyond the sequence length\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m o \u001b[38;5;241m*\u001b[39m mask\n",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m, in \u001b[0;36mgenerate_mask\u001b[0;34m(input_tensor, masks)\u001b[0m\n\u001b[1;32m     23\u001b[0m batch_size, channels, max_seqlen \u001b[38;5;241m=\u001b[39m input_tensor\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Expand the binary mask to match the input tensor shape (batch_size x features x max_seqlen)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m conv_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv_mask\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39minput_tensor\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1000) must match the existing size (908) at non-singleton dimension 2.  Target sizes: [32, 256, 1000].  Tensor sizes: [32, 1, 908]"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of model paths\n",
    "model_paths = [\n",
    "    \n",
    "    \"./weights/seq/(onehot)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \"./weights/seq/(onehot_meiler)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "   \n",
    "\n",
    "    \"./weights/seq/(esm35M)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \"./weights/seq/(esm35M)_(combinedloss)_(none)/\",\n",
    "\n",
    "    \"./weights/seq/(protbert)_(combinedloss)_(local_3block256dim)_(global_1layer128_4head)/\",\n",
    "    \"./weights/seq/(protbert)_(combinedloss)_(none)/\"\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "for path in model_paths:\n",
    "    # Load the config for the current model\n",
    "    with open(path + 'config.json', 'r') as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = Aggrepred(config)\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    # Load the model weights from the checkpoint\n",
    "    _, _ = load_model_from_checkpoint(model, optimizer, path + 'model_best.pt', device)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, metrics, preds, tar = evaluate(model, test_dataloader,combined_loss, config['encode_mode'] ,device)\n",
    "\n",
    "    # Save metrics of the best model\n",
    "    with open(path + 'result.json', 'w') as json_file:\n",
    "        json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "    print(f\"Processed model in path: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[10][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar[10][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseqs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
